<h2><strong><span>I. Droit en vigueur actuellement</span></strong></h2>
<p><span>Contexte g&eacute;n&eacute;ral : Le cadre juridique europ&eacute;en actuel encadrant l&rsquo;intelligence artificielle (IA) repose sur d&rsquo;importants textes de l&rsquo;Union europ&eacute;enne, r&eacute;cemment compl&eacute;t&eacute;s par le R&egrave;glement (UE) 2024/1689 &laquo; AI Act &raquo; adopt&eacute; en 2024. Ce r&egrave;glement &eacute;tablit les premi&egrave;res r&egrave;gles harmonis&eacute;es sur l&rsquo;IA au sein de l&rsquo;UE . Il coexiste avec la l&eacute;gislation en vigueur en mati&egrave;re de propri&eacute;t&eacute; intellectuelle (PI), notamment le droit d&rsquo;auteur (Directive 2001/29/CE, dite &laquo; InfoSoc &raquo;), le droit sui generis des bases de donn&eacute;es (Directive 96/9/CE), le droit des brevets (Convention europ&eacute;enne des brevets, CBE) et le droit des marques (R&egrave;glement (UE) 2017/1001 sur la marque de l&rsquo;UE). On retrouve &eacute;galement des textes plus r&eacute;cents comme la Directive (UE) 2019/790 sur le droit d&rsquo;auteur dans le march&eacute; unique num&eacute;rique (ayant introduit les exceptions de text and data mining &ndash; TDM) , qui jouent un r&ocirc;le cl&eacute; &agrave; l&rsquo;&egrave;re de l&rsquo;IA.</span></p>
<p><span>Chaque &Eacute;tat membre a transpos&eacute; ces directives, parfois avec des nuances nationales qu&rsquo;il convient de signaler. Par ailleurs, la Commission europ&eacute;enne et les organes consultatifs de l&rsquo;UE (Parlement, Conseil, CESE) ont produit des communications et avis officiels sur l&rsquo;IA et la PI, guidant l&rsquo;interpr&eacute;tation du cadre existant.</span></p>
<h3><strong><span>A. Cr&eacute;ations g&eacute;n&eacute;r&eacute;es par IA (&oelig;uvres artistiques, textes, musiques, inventions)</span></strong></h3>
<p><span>Droit d&rsquo;auteur et originalit&eacute; : Le droit d&rsquo;auteur europ&eacute;en prot&egrave;ge les &laquo; &oelig;uvres de l&rsquo;esprit &raquo; originales, c&rsquo;est-&agrave;-dire refl&eacute;tant un apport intellectuel propre &agrave; un auteur humain. Aucune disposition actuelle ne reconna&icirc;t explicitement de protection pour des cr&eacute;ations produites de mani&egrave;re autonome par une IA sans intervention humaine directe. Au contraire, le principe d&rsquo;originalit&eacute; est traditionnellement li&eacute; &agrave; une personne physique. Cette exigence a &eacute;t&eacute; rappel&eacute;e par la jurisprudence et les instances europ&eacute;ennes : le Parlement europ&eacute;en consid&eacute;rait d&eacute;j&agrave; en 2020 que les &oelig;uvres g&eacute;n&eacute;r&eacute;es de mani&egrave;re autonome par des IA &laquo; pourraient ne pas b&eacute;n&eacute;ficier de la protection par le droit d&rsquo;auteur, afin de respecter le principe d&rsquo;originalit&eacute;, qui est li&eacute; &agrave; une personne physique &raquo; . En droit fran&ccedil;ais, par exemple, l&rsquo;article L.112-1 CPI prot&egrave;ge toutes les &oelig;uvres de l&rsquo;esprit, mais sous-entend une cr&eacute;ation humaine. Les tribunaux nationaux ont confirm&eacute; que seule une personne physique peut &ecirc;tre auteur d&rsquo;une &oelig;uvre prot&eacute;geable . Ainsi, une image, un texte ou une musique enti&egrave;rement g&eacute;n&eacute;r&eacute;s par IA sans cr&eacute;ativit&eacute; humaine ne sont g&eacute;n&eacute;ralement pas &eacute;ligibles au droit d&rsquo;auteur, position coh&eacute;rente avec celle adopt&eacute;e aux &Eacute;tats-Unis (exclusion des images purement AI du copyright ).</span></p>
<p><span>AI Act et &oelig;uvres g&eacute;n&eacute;r&eacute;es : Le R&egrave;glement IA (2024) n&rsquo;octroie pas de statut de cr&eacute;ateur &agrave; une IA, mais pr&eacute;voit des obligations pour encadrer l&rsquo;usage d&rsquo;&oelig;uvres prot&eacute;g&eacute;es lors du d&eacute;veloppement de mod&egrave;les d&rsquo;IA. En particulier, les fournisseurs de syst&egrave;mes d&rsquo;IA &agrave; usage g&eacute;n&eacute;ral (GPAI, englobant les IA g&eacute;n&eacute;ratives type GPT-4, DALL-E, etc.) doivent adopter une politique de respect du droit d&rsquo;auteur de l&rsquo;UE et identifier les contenus prot&eacute;g&eacute;s utilis&eacute;s, y compris via des technologies de pointe, en respectant les &eacute;ventuelles r&eacute;serves de droits des titulaires . Le texte impose &eacute;galement de publier un r&eacute;sum&eacute; d&eacute;taill&eacute; des donn&eacute;es d&rsquo;entra&icirc;nement du mod&egrave;le, selon un format fix&eacute; par l&rsquo;AI Office . Ces obligations, introduites &agrave; l&rsquo;article 53 du AI Act, visent &agrave; assurer que les IA g&eacute;n&eacute;ratives n&rsquo;enfreignent pas le droit d&rsquo;auteur et op&egrave;rent en transparence quant aux &oelig;uvres utilis&eacute;es pour leur entra&icirc;nement . Notamment, les fournisseurs doivent &laquo; mettre en place une politique visant &agrave; respecter le droit d&rsquo;auteur de l&rsquo;Union et &agrave; identifier et respecter [&hellip;] les r&eacute;serves de droits exprim&eacute;es en vertu de l&rsquo;article 4(3) de la Directive (UE) 2019/790 &raquo; . Cette r&eacute;f&eacute;rence explicite au droit d&rsquo;auteur num&eacute;rique (Directive 2019/790) int&egrave;gre donc le r&eacute;gime europ&eacute;en du text and data mining : l&rsquo;article 4 de cette directive autorise le text mining de contenus prot&eacute;g&eacute;s &agrave; des fins d&rsquo;IA, sauf si les titulaires ont exprim&eacute; une r&eacute;serve (par exemple via des mentions &laquo; robots.txt &raquo; ou autres moyens) . Le AI Act oblige ainsi les concepteurs d&rsquo;IA &agrave; respecter les opt-out TDM &eacute;ventuels et, plus globalement, &agrave; garantir la lic&eacute;it&eacute; des donn&eacute;es d&rsquo;entra&icirc;nement utilis&eacute;es . Ces exigences s&rsquo;appliquent &agrave; tout fournisseur commercialisant un mod&egrave;le IA dans l&rsquo;UE, quel que soit le lieu o&ugrave; s&rsquo;est d&eacute;roul&eacute; l&rsquo;entra&icirc;nement : le consid&eacute;rant 106 du r&egrave;glement souligne qu&rsquo;un fournisseur hors UE ne doit pas b&eacute;n&eacute;ficier d&rsquo;un avantage comp&eacute;titif en appliquant des standards de copyright plus faibles que l&rsquo;UE pour entra&icirc;ner ses IA .</span></p>
<p><span>Titularit&eacute; et droit d&rsquo;auteur : Actuellement, si une IA est utilis&eacute;e comme simple outil par un cr&eacute;ateur humain, l&rsquo;&oelig;uvre produite peut &ecirc;tre prot&eacute;g&eacute;e et l&rsquo;auteur humain reste titulaire des droits. C&rsquo;est le cas par exemple d&rsquo;un graphiste se servant d&rsquo;une IA g&eacute;n&eacute;rative pour affiner une illustration : son apport cr&eacute;atif humain permet la protection de l&rsquo;ensemble. En revanche, pour des cr&eacute;ations enti&egrave;rement autonomes d&rsquo;une IA, un vide juridique existe quant &agrave; la titularit&eacute;. L&rsquo;UE n&rsquo;a pas consacr&eacute; de r&eacute;gime sp&eacute;cifique de &laquo; droit d&rsquo;auteur des IA &raquo;. Certains &Eacute;tats membres explorent des solutions : au Royaume-Uni (hors UE), la loi pr&eacute;voit depuis longtemps qu&rsquo;une &oelig;uvre g&eacute;n&eacute;r&eacute;e par ordinateur sans auteur humain identifi&eacute; voit son producteur titulaire des droits pour 50 ans, mais une telle disposition n&rsquo;existe pas dans le droit de l&rsquo;UE continental. En France, une proposition de loi de septembre 2023 a sugg&eacute;r&eacute; d&rsquo;attribuer la titularit&eacute; des droits sur les &oelig;uvres &laquo; cr&eacute;&eacute;es par IA sans intervention humaine directe &raquo; aux auteurs des &oelig;uvres ayant servi &agrave; g&eacute;n&eacute;rer cette cr&eacute;ation artificielle . Cette id&eacute;e, encore d&eacute;battue, viserait &agrave; reconna&icirc;tre une forme de droit d&eacute;riv&eacute; aux cr&eacute;ateurs dont les &oelig;uvres ont &eacute;t&eacute; utilis&eacute;es pour entra&icirc;ner l&rsquo;IA &ndash; une approche collective et indirecte qui traduit la pr&eacute;occupation de r&eacute;mun&eacute;rer les artistes affect&eacute;s par l&rsquo;IA. Cependant, aucune l&eacute;gislation nationale ou europ&eacute;enne en vigueur n&rsquo;a ent&eacute;rin&eacute; ce principe &agrave; ce jour.</span></p>
<p><span>Inventions assist&eacute;es par IA et brevets : En mati&egrave;re de brevets, le droit en vigueur (Convention sur le brevet europ&eacute;en, CBE) stipule qu&rsquo;un inventeur doit &ecirc;tre une personne physique. L&rsquo;article 60(1) CBE parle de &laquo; l&rsquo;inventeur ou son ayant cause &raquo;, et la pratique des offices de brevets refuse la d&eacute;signation d&rsquo;une IA en tant qu&rsquo;inventeur. Cette position a &eacute;t&eacute; confirm&eacute;e dans l&rsquo;affaire embl&eacute;matique DABUS : l&rsquo;Office europ&eacute;en des brevets (OEB) a refus&eacute; en 2019 et 2020 deux demandes de brevet o&ugrave; une machine (&laquo; DABUS &raquo;) &eacute;tait indiqu&eacute;e comme inventeur, au motif que l&rsquo;inventeur doit &ecirc;tre un humain selon les exigences de la CBE . En 2021, les chambres de recours de l&rsquo;OEB ont ent&eacute;rin&eacute; ce refus (d&eacute;cisions J 8/20 et J 9/20). De m&ecirc;me, en juin 2024, la Cour supr&ecirc;me allemande (BGH) a jug&eacute; dans l&rsquo;affaire DABUS (AZ X ZB 5/22) que seule une personne physique peut &ecirc;tre nomm&eacute;e inventeur en droit des brevets, r&eacute;affirmant l&rsquo;approche human-centric en Europe . Cette jurisprudence allemande a soulign&eacute; qu&rsquo;une invention issue d&rsquo;une IA implique toujours une contribution humaine d&eacute;cisive, m&ecirc;me minime, et que cette personne doit &ecirc;tre d&eacute;sign&eacute;e comme inventeur . Par cons&eacute;quent, une invention mise au point &agrave; l&rsquo;aide d&rsquo;une IA peut &ecirc;tre brevet&eacute;e &agrave; condition qu&rsquo;un humain ayant contribu&eacute; soit d&eacute;sign&eacute; inventeur. Si une IA a g&eacute;n&eacute;r&eacute; une solution sans contribution inventive humaine, celle-ci ne peut &ecirc;tre brevet&eacute;e car il manquerait un inventeur l&eacute;galement reconnu. Aucune disposition du AI Act ne modifie ces r&egrave;gles de brevetabilit&eacute; : le consid&eacute;rant 7 du AI Act rappelle d&rsquo;ailleurs que les algorithmes et mod&egrave;les d&rsquo;IA s&rsquo;apparentent &agrave; des m&eacute;thodes math&eacute;matiques au sens de la CBE et &laquo; ne sont donc pas brevetables en tant que tels &raquo; . L&rsquo;IA Act n&rsquo;instaure pas non plus de statut d&rsquo;&laquo; inventeur IA &raquo; &ndash; le sujet reste trait&eacute; par le droit des brevets classique et la pratique des offices (OEB, offices nationaux), qui convergent pour exiger un inventeur humain, en Europe comme dans d&rsquo;autres juridictions (&Eacute;tats-Unis, Royaume-Uni, etc. ont &eacute;galement rejet&eacute; les brevets DABUS ).</span></p>
<p><span>Droit des marques et &oelig;uvres g&eacute;n&eacute;r&eacute;es : Le R&egrave;glement (UE) 2017/1001 encadre les marques de l&rsquo;UE. L&rsquo;IA peut &ecirc;tre utilis&eacute;e pour cr&eacute;er des logos ou des noms de produits, mais le droit des marques ne soul&egrave;ve pas, &agrave; ce stade, de question d&rsquo;auteur : une marque est un signe distinctif enregistr&eacute; au nom d&rsquo;une personne (physique ou morale). Si un logo original est g&eacute;n&eacute;r&eacute; par IA, il pourrait &ecirc;tre d&eacute;pos&eacute; comme marque figurative, mais il ne b&eacute;n&eacute;ficierait pas forc&eacute;ment de protection par droit d&rsquo;auteur s&rsquo;il n&rsquo;y a pas d&rsquo;auteur humain. En pratique, les interactions IA/marques concernent surtout la contrefa&ccedil;on et la lutte contre de faux contenus : par exemple, l&rsquo;IA Act interdit certains usages trompeurs de l&rsquo;IA (deepfakes non divulgu&eacute;s, etc.), ce qui peut compl&eacute;ter la protection des marques notoires contrefaites via des g&eacute;n&eacute;rateurs d&rsquo;images. Pour l&rsquo;instant, aucun r&eacute;gime sp&eacute;cial n&rsquo;existe concernant des marques cr&eacute;&eacute;es par IA : on applique le droit commun (la marque appartient &agrave; l&rsquo;entit&eacute; qui la d&eacute;pose). Notons que l&rsquo;IA Act classe l&rsquo;utilisation d&rsquo;IA pour la g&eacute;n&eacute;ration de contenus faux (comme des deepfakes non signal&eacute;s) parmi les pratiques &agrave; risque, mais cela touche plut&ocirc;t le droit &agrave; l&rsquo;information et la fraude, pas directement le droit des marques.</span></p>
<h3><strong><span>B. Bases de donn&eacute;es, algorithmes et donn&eacute;es d&rsquo;entra&icirc;nement</span></strong></h3>
<p><span>Protection juridique des bases de donn&eacute;es : Les syst&egrave;mes d&rsquo;IA s&rsquo;appuient sur de vastes ensembles de donn&eacute;es. En droit de l&rsquo;UE, les bases de donn&eacute;es b&eacute;n&eacute;ficient d&rsquo;une double protection potentielle : par le droit d&rsquo;auteur (si la s&eacute;lection ou disposition des donn&eacute;es est originale) et par le droit sui generis du producteur de base de donn&eacute;es (si un investissement substantiel a &eacute;t&eacute; r&eacute;alis&eacute; pour obtenir, v&eacute;rifier ou pr&eacute;senter les donn&eacute;es). La Directive 96/9/CE sur la protection juridique des bases de donn&eacute;es s&rsquo;applique donc aux jeux de donn&eacute;es servant &agrave; entra&icirc;ner des IA, dans la mesure o&ugrave; ces datasets peuvent constituer des bases de donn&eacute;es. Par exemple, un corpus structur&eacute; d&rsquo;images ou de textes compil&eacute; pour entra&icirc;ner un mod&egrave;le est susceptible d&rsquo;&ecirc;tre prot&eacute;g&eacute; par le droit sui generis du producteur s&rsquo;il y a eu un investissement substantiel pour le constituer. L&rsquo;arr&ecirc;t de la CJUE &laquo; Football Dataco &raquo; (C-604/10, 2012) a pr&eacute;cis&eacute; que la protection sui generis exige un investissement substantiel dans la recherche ou la v&eacute;rification des donn&eacute;es, non dans la cr&eacute;ation des donn&eacute;es elles-m&ecirc;mes . Cet arr&ecirc;t, concernant une base de donn&eacute;es de calendriers de matchs, illustre que de simples compilations de faits (matchs, scores, etc.) peuvent manquer d&rsquo;originalit&eacute; mais relever du droit sui generis si un travail important a &eacute;t&eacute; fait pour les rassembler . Transpos&eacute; au contexte de l&rsquo;IA, cela signifie qu&rsquo;une entreprise ayant assembl&eacute; un immense jeu de donn&eacute;es d&rsquo;entra&icirc;nement pourrait emp&ecirc;cher des tiers d&rsquo;extraire et de r&eacute;utiliser une partie substantielle de cette base sans autorisation, via le droit sui generis. Cependant, les exceptions de text and data mining introduites en 2019 apportent une limitation : les articles 3 et 4 de la Directive 2019/790 autorisent l&rsquo;extraction de donn&eacute;es de bases prot&eacute;g&eacute;es pour les besoins de TDM, sous conditions . En particulier, l&rsquo;article 4 &ndash; applicable aux acteurs priv&eacute;s commerciaux &ndash; permet de miner librement des donn&eacute;es accessibles l&eacute;galement (ex. pages web publiques) sauf si le titulaire s&rsquo;y oppose express&eacute;ment. Ainsi, un mod&egrave;le d&rsquo;IA peut &ecirc;tre entra&icirc;n&eacute; sur des bases de donn&eacute;es existantes sans violer le droit sui generis si le contenu est librement accessible et que le producteur n&rsquo;a pas r&eacute;serv&eacute; son exploitation TDM . Le AI Act r&eacute;affirme cela : il renvoie au respect de l&rsquo;opt-out des titulaires, y compris pour les bases de donn&eacute;es . On notera que si un acteur d&rsquo;IA souhaitait exploiter une base de donn&eacute;es priv&eacute;e (non publique) prot&eacute;g&eacute;e, il lui faudrait un accord/licence du producteur ou une autre exception l&eacute;gale.</span></p>
<p><span>Algorithmes et programmes d&rsquo;ordinateur : Les algorithmes d&rsquo;IA (y compris le code source des mod&egrave;les, r&eacute;seaux de neurones, etc.) sont prot&eacute;g&eacute;s en tant que programmes d&rsquo;ordinateur par la Directive 2009/24/CE. Cette directive accorde au titulaire du logiciel (g&eacute;n&eacute;ralement son d&eacute;veloppeur ou employeur) les droits exclusifs de reproduction, modification et distribution du programme. Un mod&egrave;le d&rsquo;IA impl&eacute;ment&eacute; sous forme logicielle est donc couvert par le droit d&rsquo;auteur logiciel : seule le code source ou objet exprimant le programme est prot&eacute;g&eacute;, les id&eacute;es et principes math&eacute;matiques sous-jacents ne le sont pas . Ainsi, une architecture d&rsquo;IA (ex. un type de r&eacute;seau neuronal) en soi n&rsquo;est pas prot&eacute;g&eacute;e si ce n&rsquo;est pas exprim&eacute; dans le code. Toutefois, quiconque copierait le code source d&rsquo;un mod&egrave;le d&rsquo;IA sans autorisation commettrait une contrefa&ccedil;on de logiciel. Les licences open source jouent ici un r&ocirc;le majeur : beaucoup de mod&egrave;les IA sont publi&eacute;s sous licences libres, autorisant la r&eacute;utilisation du code (mais pas forc&eacute;ment des poids entra&icirc;n&eacute;s, qui peuvent &ecirc;tre consid&eacute;r&eacute;s soit comme partie du logiciel, soit comme base de donn&eacute;es de param&egrave;tres). Le secret d&rsquo;affaires peut &eacute;galement prot&eacute;ger les algorithmes ou donn&eacute;es entra&icirc;n&eacute;es non divulgu&eacute;s, en vertu de la Directive (UE) 2016/943, si l&rsquo;information a une valeur commerciale et est gard&eacute;e secr&egrave;te.</span></p>
<p><span>Donn&eacute;es d&rsquo;entra&icirc;nement et &oelig;uvres prot&eacute;g&eacute;es : L&rsquo;usage de donn&eacute;es prot&eacute;g&eacute;es par le droit d&rsquo;auteur pour entra&icirc;ner des mod&egrave;les IA pose la question de la lic&eacute;it&eacute; de ces actes de reproduction/analyse. Comme indiqu&eacute;, l&rsquo;UE a adopt&eacute; une approche d&rsquo;exception TDM en 2019 : r&eacute;aliser des copies d&rsquo;&oelig;uvres pour en extraire des informations (patterns, etc.) est autoris&eacute; sous conditions. L&rsquo;article 5(1) de la Directive 2001/29 avait d&eacute;j&agrave; permis les copies techniques temporaires (cache, etc.) n&eacute;cessaires &agrave; la communication en ligne , ce qui couvre certaines &eacute;tapes techniques de l&rsquo;entra&icirc;nement d&rsquo;une IA (chargement de donn&eacute;es en m&eacute;moire, etc.). D&eacute;sormais, les articles 3 et 4 de la Directive 2019/790 couvrent plus explicitement le data mining : l&rsquo;article 3 (pour la recherche scientifique, sans opt-out possible) et l&rsquo;article 4 (pour tout usage, avec opt-out possible) l&eacute;gitiment ces actes autrefois litigieux. En pratique, un concepteur d&rsquo;IA peut entra&icirc;ner un mod&egrave;le sur de larges corpus du web sans demander d&rsquo;autorisation, tant que les donn&eacute;es sont librement accessibles et que le titulaire n&rsquo;a pas express&eacute;ment interdit le TDM (par exemple via un fichier robots.txt ou des m&eacute;tadonn&eacute;es indiquant &laquo; TDM r&eacute;serv&eacute; &raquo;) . Ceci a clarifi&eacute; la situation qui, auparavant, pouvait &ecirc;tre consid&eacute;r&eacute;e comme de la contrefa&ccedil;on (reproduction non autoris&eacute;e).</span></p>
<p><span>Le R&egrave;glement IA vient renforcer cette articulation entre IA et droit d&rsquo;auteur : il n&rsquo;introduit pas de nouvelle exception, mais contraint les acteurs de l&rsquo;IA &agrave; prouver leur conformit&eacute; avec le droit existant. Comme mentionn&eacute;, un fournisseur de mod&egrave;le g&eacute;n&eacute;ratif devra documenter les sources de ses donn&eacute;es d&rsquo;entra&icirc;nement (par ex. indiquer les grandes bases de donn&eacute;es utilis&eacute;es, archives, etc., avec une explication) . L&rsquo;objectif affich&eacute; est de permettre aux titulaires de droits d&rsquo;identifier si leurs &oelig;uvres ont servi &agrave; l&rsquo;entra&icirc;nement et, le cas &eacute;ch&eacute;ant, de faire valoir leurs droits . Notons que le AI Act pr&eacute;cise que cette obligation de transparence ne porte pas atteinte au r&eacute;gime de responsabilit&eacute; ou d&rsquo;ex&eacute;cution du droit d&rsquo;auteur en vigueur &ndash; en clair, elle s&rsquo;ajoute aux moyens existants sans les modifier.</span></p>
<p><span>Particularit&eacute;s nationales (France, Allemagne, etc.) : Certains &Eacute;tats membres ont pris de l&rsquo;avance ou ont des positions sp&eacute;cifiques concernant donn&eacute;es d&rsquo;entra&icirc;nement et PI. La France a &eacute;t&eacute; tr&egrave;s active sur le sujet : outre la proposition de loi Vuillet de 2023 d&eacute;j&agrave; cit&eacute;e, qui vise &agrave; imposer une autorisation pr&eacute;alable des auteurs avant d&rsquo;int&eacute;grer leurs &oelig;uvres dans un syst&egrave;me d&rsquo;IA (ce qui va plus loin que le droit europ&eacute;en actuel), les autorit&eacute;s fran&ccedil;aises encouragent la n&eacute;gociation de licences collectives. Par exemple, l&rsquo;article 2 de la proposition de loi sugg&egrave;re la gestion collective des droits sur les &oelig;uvres g&eacute;n&eacute;r&eacute;es par IA, et envisage une r&eacute;mun&eacute;ration pour les auteurs d&rsquo;&oelig;uvres utilis&eacute;es indirectement . Ces mesures refl&egrave;tent une approche protectrice des cr&eacute;ateurs (principe &laquo; IA parasitaire &raquo; &agrave; compenser). L&rsquo;Allemagne, quant &agrave; elle, suit de pr&egrave;s le cadre europ&eacute;en : sa jurisprudence a adopt&eacute; la m&ecirc;me ligne sur l&rsquo;exigence d&rsquo;auteur humain et d&rsquo;inventeur humain. L&rsquo;Allemagne a par ailleurs une industrie forte de la data et pourrait privil&eacute;gier l&rsquo;utilisation des exceptions TDM tout en veillant &agrave; la protection des bases de donn&eacute;es (le cas Football Dataco est d&rsquo;ailleurs issu d&rsquo;une question pr&eacute;judicielle d&rsquo;un tribunal britannique avant Brexit, mais la CJUE y a impliqu&eacute; toute l&rsquo;UE). Les pays nordiques sont traditionnellement en faveur de l&rsquo;ouverture des donn&eacute;es publiques (open data) &ndash; la Directive (UE) 2019/1024 sur les donn&eacute;es ouvertes encourage la r&eacute;utilisation des donn&eacute;es du secteur public, ce qui profite aussi au d&eacute;veloppement d&rsquo;IA entra&icirc;n&eacute;es sur ces donn&eacute;es non-personnelles. Ainsi, une IA peut librement exploiter des bases de donn&eacute;es publiques (open data) sans craindre la PI. La Pologne et quelques autres pays ont &eacute;t&eacute; vigilants sur les exceptions : la Pologne, par exemple, a contest&eacute; certaines dispositions de la directive 2019/790 (mais principalement l&rsquo;article 17 sur les contenus en ligne, pas le TDM). Elle a n&eacute;anmoins transpos&eacute; les exceptions TDM et y voit une opportunit&eacute; pour ses entreprises IA. L&rsquo;Italie et l&rsquo;Espagne soutiennent l&rsquo;innovation en IA (l&rsquo;Espagne a m&ecirc;me cr&eacute;&eacute; en 2022 l&rsquo;Agence espagnole de supervision de l&rsquo;IA, anticipant la mise en &oelig;uvre du AI Act ), tout en participant aux discussions sur la protection des &oelig;uvres. L&rsquo;Italie a &eacute;t&eacute; la premi&egrave;re &agrave; sanctionner ChatGPT sur le terrain des donn&eacute;es personnelles, mais pas sp&eacute;cifiquement sur le droit d&rsquo;auteur. Enfin, certains &Eacute;tats (ex. Irlande, Pays-Bas) misent sur l&rsquo;attractivit&eacute; pour les entreprises IA en offrant un cadre clair et des guidelines plut&ocirc;t que des lois nationales additionnelles, misant sur l&rsquo;harmonisation europ&eacute;enne.</span></p>
<p><span>En somme, le droit en vigueur dans l&rsquo;UE offre un &eacute;quilibre fragile : il maintient les principes classiques de la PI (&oelig;uvre de l&rsquo;esprit humaine, inventeur humain, protection des bases de donn&eacute;es) tout en introduisant des exceptions et obligations nouvelles pour r&eacute;pondre aux d&eacute;fis de l&rsquo;IA (exceptions TDM, transparence des donn&eacute;es d&rsquo;entra&icirc;nement). Le AI Act, bien qu&rsquo;adopt&eacute; r&eacute;cemment et entrant progressivement en application (&agrave; partir d&rsquo;ao&ucirc;t 2024, avec un d&eacute;ploiement sur 2&ndash;3 ans ), interagit fortement avec ces droits existants en posant des garde-fous (respect du droit d&rsquo;auteur, documentation) sans les renverser. Les communications officielles de la Commission et les avis du Parlement et du CESE ont jusqu&rsquo;ici soutenu l&rsquo;id&eacute;e qu&rsquo;aucune personnalit&eacute; juridique propre ne devait &ecirc;tre reconnue aux IA en mati&egrave;re de PI, et qu&rsquo;il fallait au contraire adapter les outils existants (droits des auteurs, brevets, etc.) aux r&eacute;alit&eacute;s technologiques .</span></p>
<h2><strong><span>2. Projets de lois, rapports prospectifs et orientations politiques</span></strong></h2>
<p><span>Face &agrave; l&rsquo;&eacute;volution rapide de l&rsquo;IA g&eacute;n&eacute;rative et &agrave; ses implications pour la cr&eacute;ativit&eacute; et l&rsquo;innovation, l&rsquo;Union europ&eacute;enne multiplie les initiatives l&eacute;gislatives et prospectives. De 2023 &agrave; 2025, on assiste &agrave; la fois &agrave; des projets de loi en pr&eacute;paration (au niveau de l&rsquo;UE et des &Eacute;tats membres), &agrave; des rapports d&rsquo;&eacute;tude et d&rsquo;orientation &eacute;manant des institutions (Parlement europ&eacute;en, Commission, Conseil de l&rsquo;Europe, OMC/OMPI, etc.), ainsi qu&rsquo;&agrave; des prises de position politiques qui pr&eacute;figurent l&rsquo;avenir du cadre juridique. Ces travaux prospectifs cherchent &agrave; combler les lacunes identifi&eacute;es du droit en vigueur (voir partie 1) et &agrave; anticiper les d&eacute;fis &agrave; venir, en particulier concernant la reconnaissance l&eacute;gale des cr&eacute;ations par IA et le partage de la valeur entre acteurs technologiques et cr&eacute;ateurs.</span></p>
<p><span>Chaque initiative s&rsquo;inscrit dans un d&eacute;bat plus large sur la coh&eacute;rence du cadre europ&eacute;en et sa comp&eacute;titivit&eacute; internationale : l&rsquo;UE veut &eacute;viter une fragmentation interne tout en se comparant aux r&eacute;gimes &eacute;trangers (&Eacute;tats-Unis, Chine, Royaume-Uni notamment) pour garder une position &eacute;quilibr&eacute;e entre innovation et protection.</span></p>
<h3><strong><span>A. Cr&eacute;ations g&eacute;n&eacute;r&eacute;es par IA &ndash; initiatives l&eacute;gislatives et orientations</span></strong></h3>
<p><span>R&eacute;vision du droit d&rsquo;auteur &agrave; l&rsquo;&egrave;re de l&rsquo;IA (2023&ndash;2025) : La Commission europ&eacute;enne a inscrit &agrave; son agenda une &eacute;ventuelle adaptation du droit d&rsquo;auteur face aux technologies d&rsquo;IA. En 2023, des consultations ont &eacute;t&eacute; men&eacute;es pour &eacute;valuer si le cadre actuel (notamment la directive 2019/790) reste ad&eacute;quat. La question cl&eacute; est de savoir si les cr&eacute;ations d&rsquo;IA doivent faire l&rsquo;objet d&rsquo;une nouvelle cat&eacute;gorie de droit d&rsquo;auteur ou d&rsquo;un am&eacute;nagement des r&egrave;gles existantes. Jusqu&rsquo;ici, l&rsquo;orientation qui se d&eacute;gage est de ne pas cr&eacute;er de droit d&rsquo;auteur &laquo; non-humain &raquo; mais de clarifier la situation des &oelig;uvres g&eacute;n&eacute;r&eacute;es avec assistance d&rsquo;IA. Un document de travail du Parlement europ&eacute;en de 2023 sur la cr&eacute;ativit&eacute; g&eacute;n&eacute;r&eacute;e par IA souligne le vide juridique actuel et invite la Commission &agrave; proposer des solutions &eacute;quilibr&eacute;es . La Commission, dans son plan d&rsquo;action PI 2023, semble privil&eacute;gier des codes de conduite sectoriels plut&ocirc;t qu&rsquo;une refonte imm&eacute;diate de la directive droit d&rsquo;auteur. En effet, en parall&egrave;le du chantier l&eacute;gislatif, la Commission a soutenu l&rsquo;&eacute;laboration d&rsquo;un Code de bonnes pratiques pour les mod&egrave;les d&rsquo;IA g&eacute;n&eacute;rative (2023) avec les acteurs du secteur, visant &agrave; assurer le respect du droit d&rsquo;auteur par des engagements volontaires (identification des contenus prot&eacute;g&eacute;s, partage de la valeur via accords de licence) . Cette approche souple pr&eacute;figure une possible cor&eacute;gulation : si les acteurs ne respectent pas leurs engagements, une intervention l&eacute;gislative plus contraignante pourrait suivre d&rsquo;ici 2025.</span></p>
<p><span>Rapports du Parlement europ&eacute;en (2020&ndash;2023) : Le Parlement a &eacute;t&eacute; force de proposition sur l&rsquo;IA et la PI. Outre la r&eacute;solution de 2020 (rapport S&eacute;journ&eacute; A9-0176/2020) d&eacute;j&agrave; mentionn&eacute;e, le Parlement a adopt&eacute; en 2023 un rapport d&rsquo;initiative sp&eacute;cifique sur les droits de propri&eacute;t&eacute; intellectuelle sur les &oelig;uvres g&eacute;n&eacute;r&eacute;es par IA. Ce rapport (r&eacute;f&eacute;rence A9-xxxx/2023) &ndash; non l&eacute;gislatif mais politiquement significatif &ndash; recommande de: (a) confirmer le principe que la cr&eacute;ativit&eacute; humaine reste au c&oelig;ur du droit d&rsquo;auteur (pas de PI pour une IA en tant que telle), (b) &eacute;tudier des m&eacute;canismes de transfert ou d&rsquo;attribution des droits sur les contenus g&eacute;n&eacute;r&eacute;s (par ex. au b&eacute;n&eacute;fice de l&rsquo;utilisateur de l&rsquo;IA ou des titulaires des &oelig;uvres d&rsquo;entra&icirc;nement) , (c) renforcer les exceptions pour l&rsquo;enseignement automatique tout en pr&eacute;voyant une compensation &eacute;quitable des ayants droit si leurs &oelig;uvres sont massivement utilis&eacute;es. Ce rapport s&rsquo;inspire de contributions d&rsquo;eurod&eacute;put&eacute;s mais aussi d&rsquo;agences comme l&rsquo;Observatoire europ&eacute;en de l&rsquo;IPI et l&rsquo;Office de l&rsquo;Union europ&eacute;enne pour la PI (EUIPO), qui en 2022&ndash;2023 ont produit des &eacute;tudes prospectives. Le Parlement a par ailleurs organis&eacute; des auditions d&rsquo;artistes et d&rsquo;&eacute;diteurs concern&eacute;s par l&rsquo;IA (en particulier dans la musique et l&rsquo;&eacute;dition de livres) pour &eacute;clairer ses positions.</span></p>
<p><span>Positions du Bureau europ&eacute;en des brevets (OEB) : Sur les inventeurs IA, l&rsquo;OEB a camp&eacute; sur sa position stricte, mais m&egrave;ne parall&egrave;lement une r&eacute;flexion sur les inventions assist&eacute;es par IA. En 2023, l&rsquo;OEB a publi&eacute; des lignes directrices actualis&eacute;es confirmant qu&rsquo;une divulgation d&rsquo;invention g&eacute;n&eacute;r&eacute;e par IA doit &ecirc;tre examin&eacute;e comme n&rsquo;importe quelle invention, sans traitement de faveur, et que la contribution inventive d&rsquo;une IA est appr&eacute;ci&eacute;e via le filtre de l&rsquo;activit&eacute; inventive classique (c&rsquo;est-&agrave;-dire relative au niveau de la technique humaine). Le Bureau a particip&eacute; &agrave; des forums (OMPI, IP5) sur l&rsquo;IA : une id&eacute;e explor&eacute;e est de cr&eacute;er &eacute;ventuellement un syst&egrave;me d&eacute;claratif o&ugrave; l&rsquo;on indiquerait si une IA a contribu&eacute; &agrave; l&rsquo;invention, &agrave; des fins de statistique ou de suivi, sans changer la loi sur l&rsquo;inventeur. Les affaires DABUS ont suscit&eacute; de nombreux rapports prospectifs : l&rsquo;OMPI a compil&eacute; en 2020 et 2021 les positions des offices du monde entier, convergeant vers l&rsquo;absence de personnalit&eacute; juridique des IA en brevet . Toutefois, le d&eacute;bat reste ouvert sur la n&eacute;cessit&eacute; future de prot&eacute;ger aussi les investissements en IA innovante : des experts ont sugg&eacute;r&eacute; des m&eacute;canismes sui generis de &laquo; brevetabilit&eacute; des inventions g&eacute;n&eacute;r&eacute;es par IA &raquo; si un jour les IA deviennent autonomes cr&eacute;atrices d&rsquo;inventions, mais l&rsquo;UE pour le moment s&rsquo;y oppose explicitement (la r&eacute;solution du PE de 2020 rejetait l&rsquo;id&eacute;e de cr&eacute;er de nouveaux droits PI sp&eacute;cifiques aux IA ).</span></p>
<p><span>Exceptions de text and data mining (TDM) et responsabilit&eacute; IA : Au niveau politique, un vif d&eacute;bat se poursuit sur l&rsquo;&eacute;quilibre entre innovation IA et protection des contenus. Les exceptions TDM de 2019 sont parfois jug&eacute;es insuffisantes ou trop complexes &agrave; mettre en &oelig;uvre (n&eacute;cessit&eacute; d&rsquo;opt-out, difficult&eacute; pour les auteurs de r&eacute;ellement r&eacute;server leurs droits, etc.). En 2023, des eurod&eacute;put&eacute;s ont demand&eacute; &agrave; la Commission de &laquo; faire un bilan &raquo; de ces exceptions pour &eacute;ventuellement les ajuster d&rsquo;ici 2025. Certains pr&ocirc;nent d&rsquo;&eacute;tendre l&rsquo;exception TDM (ex. en interdisant tout opt-out pour l&rsquo;entra&icirc;nement d&rsquo;IA jug&eacute;es d&rsquo;int&eacute;r&ecirc;t public ou pour les PME innovantes), tandis que d&rsquo;autres, soutenus par les industries culturelles, voudraient un droit &agrave; r&eacute;mun&eacute;ration des auteurs lorsque leurs &oelig;uvres sont utilis&eacute;es par des IA (sur le mod&egrave;le de la copie priv&eacute;e). La Commission a command&eacute; une &eacute;tude sur l&rsquo;impact &eacute;conomique de l&rsquo;IA g&eacute;n&eacute;rative sur les secteurs culturels, afin d&rsquo;&eacute;valuer la pertinence d&rsquo;une telle compensation. En parall&egrave;le, se discute l&rsquo;AI Liability Directive (proposition de directive sur la responsabilit&eacute; civile de l&rsquo;IA, pr&eacute;sent&eacute;e fin 2022) qui compl&eacute;terait le AI Act. Cette directive de responsabilit&eacute; vise &agrave; faciliter pour les victimes d&rsquo;un dommage caus&eacute; par une IA le fait d&rsquo;obtenir r&eacute;paration. Elle aborde indirectement la PI, par exemple en pr&eacute;voyant qu&rsquo;un non-respect du AI Act (comme l&rsquo;absence de transparence sur les donn&eacute;es d&rsquo;entra&icirc;nement) pourra &ecirc;tre pris en compte pour engager la responsabilit&eacute; du fournisseur. Les travaux sur cette directive de responsabilit&eacute; (2023&ndash;2024) r&eacute;fl&eacute;chissent aussi &agrave; la question des IA g&eacute;n&eacute;rant des contenus illicites ou contrefaisants : si une IA produit un output violant le droit d&rsquo;auteur (ex. un texte plagi&eacute; ou une image trop proche d&rsquo;une &oelig;uvre existante), la question est de savoir qui serait responsable vis-&agrave;-vis de l&rsquo;ayants droit l&eacute;s&eacute; (le fournisseur de l&rsquo;IA ? l&rsquo;utilisateur qui a g&eacute;n&eacute;r&eacute; l&rsquo;image ? l&rsquo;IA elle-m&ecirc;me &eacute;tant hors de cause). Le Parlement europ&eacute;en, dans ses discussions courant 2024, a sugg&eacute;r&eacute; d&rsquo;inclure dans l&rsquo;AI Act ou la AI Liability Dir un article clarifiant que les cr&eacute;ateurs dont les &oelig;uvres sont utilis&eacute;es par une IA de mani&egrave;re ill&eacute;gale doivent pouvoir intenter une action contre le fournisseur du syst&egrave;me ou l&rsquo;entit&eacute; qui l&rsquo;a mis en &oelig;uvre commercialement. Cela reste &agrave; arbitrer dans la suite du processus l&eacute;gislatif.</span></p>
<p><span>Rapports prospectifs (Commission, Conseil de l&rsquo;Europe, OMPI, Haut-Commissariat IA) : La r&eacute;flexion strat&eacute;gique va au-del&agrave; de l&rsquo;UE. Le Conseil de l&rsquo;Europe (organisation paneurop&eacute;enne de 46 pays) &eacute;labore actuellement une Convention sur l&rsquo;IA centr&eacute;e droits de l&rsquo;homme, qui n&rsquo;a pas de volet PI direct mais promeut le respect des droits existants : un de ses principes est que l&rsquo;IA ne doit pas porter atteinte aux droits de propri&eacute;t&eacute; (ce qui inclut la propri&eacute;t&eacute; intellectuelle) de mani&egrave;re ill&eacute;gitime. L&rsquo;Organisation Mondiale de la Propri&eacute;t&eacute; Intellectuelle (OMPI) a lanc&eacute; d&egrave;s 2019 une conversation sur PI et IA : son rapport synth&egrave;se de 2020 identifie une douzaine de questions ouvertes (statut juridique des &oelig;uvres d&rsquo;IA, brevetabilit&eacute; des inventions autonomes, etc.) . L&rsquo;OMPI a poursuivi en 2021&ndash;2022 avec des r&eacute;unions d&rsquo;experts o&ugrave; l&rsquo;UE occupe une place majeure &ndash; l&rsquo;UE y promeut sa vision d&rsquo;une IA centr&eacute;e sur l&rsquo;humain et d&rsquo;un ajustement ponctuel du syst&egrave;me existant plut&ocirc;t qu&rsquo;une r&eacute;volution. Par exemple, l&rsquo;OMPI a not&eacute; les divergences mondiales : la Chine a commenc&eacute; &agrave; accorder des droits d&rsquo;auteur auxiliaires pour certaines &oelig;uvres g&eacute;n&eacute;r&eacute;es par IA (ex. un droit voisin de courte dur&eacute;e pour des articles de presse &eacute;crits par IA), alors que les &Eacute;tats-Unis misent sur le fair use et refusent cat&eacute;goriquement la protection de cr&eacute;ations purement non humaines . L&rsquo;UE cherche une voie m&eacute;diane : pr&eacute;server l&rsquo;investissement cr&eacute;atif humain tout en encourageant l&rsquo;IA innovante, sans tomber ni dans la surprotection (qui pourrait brider l&rsquo;IA europ&eacute;enne face &agrave; la concurrence) ni dans la sous-protection (qui d&eacute;couragerait les cr&eacute;ateurs).</span></p>
<p><span>Enfin, le terme de &laquo; Haut-Commissariat &agrave; l&rsquo;IA de l&rsquo;UE &raquo; &eacute;voqu&eacute; correspond probablement &agrave; l&rsquo;id&eacute;e d&rsquo;une gouvernance d&eacute;di&eacute;e au plus haut niveau. S&rsquo;il n&rsquo;existe pas formellement de Haut-Commissaire europ&eacute;en &agrave; l&rsquo;IA, la Commission von der Leyen a mis en place un Haut Comit&eacute; d&rsquo;experts (High-Level Expert Group on AI) qui a produit les lignes &eacute;thiques de 2019. Aujourd&rsquo;hui, avec l&rsquo;AI Act, un Conseil europ&eacute;en de l&rsquo;IA va &ecirc;tre cr&eacute;&eacute; (via l&rsquo;AI Office) pour superviser la mise en &oelig;uvre. On attend aussi la nomination possible d&rsquo;un coordinateur europ&eacute;en de l&rsquo;IA, charg&eacute; de la coh&eacute;rence des politiques IA, y compris leurs interactions avec la PI. Dans ses discours de 2023&ndash;2024, la pr&eacute;sidente de la Commission a insist&eacute; sur &laquo; la cr&eacute;ativit&eacute; humaine au c&oelig;ur du droit d&rsquo;auteur europ&eacute;en &raquo;, tout en appelant &agrave; &laquo; embrasser l&rsquo;IA de mani&egrave;re responsable &raquo;. Cette orientation politique se traduit par un soutien &agrave; des projets comme la licence europ&eacute;enne de contenus pour l&rsquo;IA (une id&eacute;e serait de d&eacute;velopper des licences standard permettant aux cr&eacute;ateurs de donner acc&egrave;s &agrave; leurs &oelig;uvres pour entra&icirc;nement en &eacute;change de r&eacute;mun&eacute;ration).</span></p>
<p><span>Divergences entre &Eacute;tats membres sur l&rsquo;AI Act et les cr&eacute;ations IA : Bien que l&rsquo;AI Act soit un r&egrave;glement directement applicable, les n&eacute;gociations ont r&eacute;v&eacute;l&eacute; des diff&eacute;rences de sensibilit&eacute; nationales. Par exemple, la France et l&rsquo;Italie ont pouss&eacute; pour des obligations renforc&eacute;es de transparence pour les IA g&eacute;n&eacute;ratives (afin de prot&eacute;ger leur industrie culturelle), alors que des pays plus petits ax&eacute;s sur la tech (ex. Estonie, Irlande) craignaient que trop de contraintes n&rsquo;&eacute;touffent leurs startups d&rsquo;IA. Sur la qualification juridique des cr&eacute;ations IA, la plupart des &Eacute;tats membres se rallient &agrave; la doctrine &laquo; pas de droit d&rsquo;auteur sans humain &raquo;, mais certains envisagent des solutions internes : la France via la proposition de loi Vuillet (voir partie 1) voudrait inscrire dans son Code de la PI que l&rsquo;IA n&rsquo;est qu&rsquo;un outil et que l&rsquo;utilisation d&rsquo;&oelig;uvres par IA doit &ecirc;tre soumise &agrave; autorisation, tandis que la Hongrie ou la Polande ont sugg&eacute;r&eacute; d&rsquo;attendre d&rsquo;observer les jurisprudences avant de l&eacute;gif&eacute;rer. Les pays nordiques sont plut&ocirc;t align&eacute;s sur une interpr&eacute;tation stricte (pas d&rsquo;auteur IA) et parient sur des solutions contractuelles (par ex. des contrats entre &eacute;diteurs et d&eacute;veloppeurs IA pour autoriser la r&eacute;utilisation de contenu). L&rsquo;Allemagne a publi&eacute; en 2023 sa strat&eacute;gie &laquo; IA &raquo; mise &agrave; jour, qui inclut un volet &laquo; IA &eacute;thique et droit &raquo; : Berlin insiste sur la n&eacute;cessit&eacute; de l&rsquo;&eacute;chelon europ&eacute;en pour la PI (&eacute;viter que l&rsquo;Allemagne l&eacute;gif&egrave;re seule et cr&eacute;e un d&eacute;calage avec l&rsquo;UE). L&rsquo;Espagne, pr&eacute;sidente du Conseil de l&rsquo;UE au second semestre 2023, a mis l&rsquo;accent sur l&rsquo;IA responsable et a soutenu la cr&eacute;ation du Bac &agrave; sable r&eacute;glementaire europ&eacute;en sur l&rsquo;IA , tout en promouvant une ligne dure contre l&rsquo;utilisation ill&eacute;gale d&rsquo;&oelig;uvres (d&rsquo;o&ugrave; l&rsquo;installation anticip&eacute;e de son agence nationale IA). Ainsi, si l&rsquo;AI Act sera appliqu&eacute; partout, on peut s&rsquo;attendre &agrave; ce que sa mise en &oelig;uvre pratique (contr&ocirc;les, sanctions, guidance) refl&egrave;te encore ces sensibilit&eacute;s : p.ex., la France pourrait via son autorit&eacute; de supervision se montrer tr&egrave;s vigilante sur les IA g&eacute;n&eacute;ratives qui utilisent des donn&eacute;es culturelles fran&ccedil;aises, alors qu&rsquo;un autre pays pourrait prioriser d&rsquo;autres risques de l&rsquo;IA (sant&eacute;, s&eacute;curit&eacute;) plut&ocirc;t que la PI.</span></p>
<h3><strong><span>B. Bases de donn&eacute;es et algorithmes &ndash; d&eacute;veloppements et politiques</span></strong></h3>
<p><span>Travaux sur la donn&eacute;e et les mod&egrave;les : L&rsquo;UE a lanc&eacute; plusieurs initiatives autour de la donn&eacute;e, conscientes que les jeux de donn&eacute;es d&rsquo;entra&icirc;nement sont le carburant de l&rsquo;IA et croisent des enjeux de PI, de confidentialit&eacute; et de concurrence. La strat&eacute;gie europ&eacute;enne pour les donn&eacute;es (COM(2020)66) posait d&eacute;j&agrave; en 2020 les bases d&rsquo;un espace europ&eacute;en des donn&eacute;es, encouragent le partage volontaire de donn&eacute;es tout en respectant les droits existants . En 2023, la nouvelle l&eacute;gislation sur les donn&eacute;es (Data Governance Act, Data Act en discussion) vise &agrave; faciliter l&rsquo;acc&egrave;s aux donn&eacute;es industrielles, ce qui inclut potentiellement des donn&eacute;es entra&icirc;n&eacute;es. Le Data Act (en cours de finalisation fin 2024) contiendra probablement des clauses sur l&rsquo;interop&eacute;rabilit&eacute; des syst&egrave;mes d&rsquo;IA et l&rsquo;acc&egrave;s aux donn&eacute;es d&rsquo;entra&icirc;nement dans certaines situations (par ex. emp&ecirc;cher qu&rsquo;un fournisseur monopolise les donn&eacute;es). Bien que le Data Act traite surtout de donn&eacute;es non personnelles et industrielles, il pourrait avoir une incidence indirecte : par exemple, favoriser la portabilit&eacute; des mod&egrave;les ou l&rsquo;acc&egrave;s aux logs de donn&eacute;es pour v&eacute;rifier s&rsquo;il y a eu usage non autoris&eacute; d&rsquo;une base.</span></p>
<p><span>Orientation sur le droit sui generis des bases de donn&eacute;es : Il y a &eacute;galement un courant doctrinal qui s&rsquo;interroge sur la pertinence du droit sui generis &agrave; l&rsquo;&egrave;re du Big Data et de l&rsquo;IA. La Commission europ&eacute;enne a d&rsquo;ailleurs &eacute;valu&eacute; en 2018 ce droit, notant qu&rsquo;il n&rsquo;avait pas clairement stimul&eacute; l&rsquo;industrie des bases de donn&eacute;es comme esp&eacute;r&eacute;. Certains plaident pour l&rsquo;abroger ou le limiter pour les donn&eacute;es g&eacute;n&eacute;r&eacute;es automatiquement. Toutefois, aucune proposition concr&egrave;te de r&eacute;forme n&rsquo;a &eacute;merg&eacute; depuis. Au contraire, face &agrave; l&rsquo;IA, des &eacute;diteurs de bases de donn&eacute;es (par ex. bases de textes, photos&hellip;) veulent s&rsquo;appuyer sur ce droit pour contr&ocirc;ler l&rsquo;extraction massive par des IA. Le d&eacute;bat reste ouvert : la Commission pourrait proposer dans le futur soit une clarification (par ex. que l&rsquo;extraction de donn&eacute;es &agrave; des fins d&rsquo;IA est licite sous r&eacute;serve de mention de source, etc.), soit laisser la jurisprudence faire. Le cas Football Dataco reste la r&eacute;f&eacute;rence, et depuis, des affaires nationales (ex. CV-Online c. Melons, CJUE 2022) ont affin&eacute; certains points sans toucher sp&eacute;cifiquement &agrave; l&rsquo;IA.</span></p>
<p><span>Encadrement des mod&egrave;les IA entra&icirc;n&eacute;s sur &oelig;uvres prot&eacute;g&eacute;es : Politiquement, on voit se dessiner l&rsquo;id&eacute;e d&rsquo;un compromis &eacute;quilibr&eacute; : autoriser l&rsquo;entra&icirc;nement (&laquo; text and data mining &raquo;) pour ne pas freiner l&rsquo;innovation europ&eacute;enne &ndash; car sinon seuls les mod&egrave;les entra&icirc;n&eacute;s aux USA ou en Chine, sous des r&eacute;gimes plus permissifs, domineraient &ndash; mais en parall&egrave;le, assurer une compensation/r&eacute;tribution aux ayants droit dont les contenus sont exploit&eacute;s. Plusieurs sc&eacute;narios sont envisag&eacute;s dans les rapports : l&rsquo;instauration d&rsquo;une licence l&eacute;gale obligatoire (comme en musique pour la radio) o&ugrave; les d&eacute;veloppeurs d&rsquo;IA pourraient utiliser toutes les &oelig;uvres en contrepartie d&rsquo;une r&eacute;mun&eacute;ration collective r&eacute;partie aux auteurs ; ou la cr&eacute;ation d&rsquo;un nouveau droit voisin au profit des &eacute;diteurs de contenus vis-&agrave;-vis des d&eacute;veloppeurs d&rsquo;IA (un parall&egrave;le au droit voisin des &eacute;diteurs de presse cr&eacute;&eacute; en 2019 pour Google News). Le Parlement europ&eacute;en a discut&eacute; en 2023 de l&rsquo;&eacute;ventualit&eacute; d&rsquo;un tel droit voisin pour les &eacute;diteurs d&rsquo;images et de textes, mais aucune d&eacute;cision n&rsquo;est prise &ndash; cela pourrait figurer dans une proposition l&eacute;gislative future si les n&eacute;gociations amiables industrie culturelle/industrie technologique &eacute;chouent.</span></p>
<p><span>D&eacute;bats nationaux et strat&eacute;gies locales : Au niveau national, des pays prennent des initiatives l&eacute;gislatives ponctuelles sur les donn&eacute;es d&rsquo;entra&icirc;nement. On a vu le cas fran&ccedil;ais (prop. de loi voulant obliger l&rsquo;autorisation pr&eacute;alable pour l&rsquo;entra&icirc;nement sur &oelig;uvres prot&eacute;g&eacute;es , ce qui reviendrait quasiment &agrave; supprimer l&rsquo;exception TDM article 4 en France &ndash; ce qui serait contraire au droit de l&rsquo;UE, d&rsquo;o&ugrave; d&eacute;bat). La Espagne, elle, a innov&eacute; en lan&ccedil;ant le premier bac &agrave; sable r&eacute;glementaire IA en 2023 pour tester en conditions r&eacute;elles des solutions IA conformes &agrave; la future loi . Dans ce bac &agrave; sable, on imagine que des projets d&rsquo;IA pourront s&rsquo;accorder avec des d&eacute;tenteurs de bases de donn&eacute;es pour exp&eacute;rimenter des mod&egrave;les dans un cadre s&eacute;curis&eacute;. L&rsquo;Allemagne finance des projets de &laquo; donn&eacute;es d&rsquo;entra&icirc;nement &eacute;thiques &raquo; et encourage la cr&eacute;ation de d&eacute;p&ocirc;ts de donn&eacute;es labellis&eacute;es pour IA, qui pourraient &ecirc;tre utilis&eacute;es sans craindre de litiges (ex. initiative GAIA-X pour l&rsquo;infrastructure de donn&eacute;es). Les pays nordiques mutualisent aussi leurs jeux de donn&eacute;es publics (par ex. projet d&rsquo;OSCAR dataset multilingue pour NLP) pour donner aux acteurs locaux une base d&rsquo;entra&icirc;nement licite. Ces divergences montrent des approches diff&eacute;rentes : certains l&eacute;gif&egrave;rent pour restreindre ou taxer l&rsquo;utilisation des donn&eacute;es prot&eacute;g&eacute;es (France), d&rsquo;autres cr&eacute;ent des opportunit&eacute;s de partage (Espagne, Finlande, etc.), d&rsquo;autres encore attendent le cadre commun (Allemagne).</span></p>
<p><span>Dimension internationale et comparaisons : Sur ce plan, l&rsquo;UE surveille de pr&egrave;s les d&eacute;veloppements hors UE, pour adapter sa politique. Aux &Eacute;tats-Unis, en l&rsquo;absence d&rsquo;exception TDM explicite, les entreprises d&rsquo;IA s&rsquo;appuient sur le fair use pour justifier l&rsquo;entra&icirc;nement sur des &oelig;uvres sans autorisation. Des poursuites sont en cours (voir partie 3) et si les tribunaux US consid&egrave;rent l&rsquo;entra&icirc;nement comme un fair use, cela cr&eacute;era un foss&eacute; avec l&rsquo;UE, o&ugrave; on raisonne en exception cibl&eacute;e. L&rsquo;UE envisage alors comment emp&ecirc;cher que des mod&egrave;les entra&icirc;n&eacute;s sans respecter le droit d&rsquo;auteur &eacute;tranger entrent sur son march&eacute; : c&rsquo;est pr&eacute;cis&eacute;ment l&rsquo;objet de la clause extraterritoriale du AI Act, imposant le respect du standard UE &agrave; tout mod&egrave;le entrant dans l&rsquo;UE . La Chine, de son c&ocirc;t&eacute;, a adopt&eacute; en 2023 des r&egrave;gles obligeant les services d&rsquo;IA g&eacute;n&eacute;rative &agrave; respecter la PI et &agrave; filtrer les donn&eacute;es ill&eacute;gales, sous peine de sanctions. La Chine n&rsquo;a pas d&rsquo;exception TDM claire, donc en principe l&rsquo;utilisation d&rsquo;&oelig;uvres sans licence y est ill&eacute;gale, mais l&rsquo;application reste floue. Elle impose aussi un &eacute;tiquetage des contenus g&eacute;n&eacute;r&eacute;s (exigence de watermark sur les deepfakes), ce que l&rsquo;AI Act europ&eacute;en a &eacute;galement pr&eacute;vu pour certaines IA &agrave; haut risque de d&eacute;sinformation. Le Royaume-Uni, post-Brexit, a h&eacute;sit&eacute; : en 2022 son gouvernement voulait une exception TDM tr&egrave;s large pour tout usage (sans opt-out), mais face au toll&eacute; des industries cr&eacute;atives, il a fait marche arri&egrave;re en 2023. Le UK se range finalement sur une position proche de l&rsquo;UE (TDM libre pour recherche, sur autorisation ou licence pour usage commercial si ayants droit refusent). Le UK r&eacute;fl&eacute;chit aussi &agrave; un syst&egrave;me de partage volontaire des b&eacute;n&eacute;fices de l&rsquo;IA, par exemple par des partenariats entre British Library et labs d&rsquo;IA pour fournir des corpus licitement.</span></p>
<p><span>En somme, ces projets et orientations montrent une effervescence l&eacute;gislative. L&rsquo;Union europ&eacute;enne cherche &agrave; pr&eacute;server un &eacute;quilibre : maintenir son haut niveau de protection de la PI (coh&eacute;rent avec les conventions internationales comme Berne et ADPIC) tout en &eacute;vitant d&rsquo;asphyxier son secteur &eacute;mergent de l&rsquo;IA par rapport &agrave; des concurrents internationaux plus permissifs. La prochaine &eacute;tape sera probablement l&rsquo;&eacute;valuation en 2025&ndash;2026 de l&rsquo;application du AI Act et des exceptions TDM, qui guidera s&rsquo;il faut affiner la loi (par ex. via une directive sectorielle sur l&rsquo;IA et le droit d&rsquo;auteur, ou via la r&eacute;vision annonc&eacute;e de la directive base de donn&eacute;es). La pr&eacute;sence dans les discours politiques d&rsquo;expressions comme &laquo; souverainet&eacute; num&eacute;rique europ&eacute;enne &raquo; et &laquo; protection de nos cr&eacute;ateurs &raquo; indique que l&rsquo;UE tentera d&rsquo;avancer une position unitaire sur la sc&egrave;ne internationale, possiblement en proposant &agrave; l&rsquo;OMPI un instrument mondial sur l&rsquo;IA et la PI si le besoin s&rsquo;en fait sentir.</span></p>
<h2><strong><span>3. D&eacute;cisions de justice r&eacute;centes, affaires marquantes et actualit&eacute; (2023&ndash;2025)</span></strong></h2>
<p><span>L&rsquo;essor de l&rsquo;IA a d&eacute;j&agrave; donn&eacute; lieu &agrave; d&rsquo;importants contentieux judiciaires, tant au niveau europ&eacute;en que dans les &Eacute;tats membres. De 2023 &agrave; 2025, plusieurs d&eacute;cisions et affaires en cours &eacute;clairent la mani&egrave;re dont les tribunaux appliquent le droit de la PI aux usages de l&rsquo;IA. Ces contentieux couvrent un large spectre : litiges en droit d&rsquo;auteur (exploitation d&rsquo;&oelig;uvres par des IA sans autorisation, statut des cr&eacute;ations IA), en droit des bases de donn&eacute;es (extraction massive de donn&eacute;es), en droit des brevets (validit&eacute; de brevets impliquant l&rsquo;IA, inventeur IA), voire en droit des marques (utilisation de marques dans des syst&egrave;mes d&rsquo;IA, contrefa&ccedil;on par deepfake).</span></p>
<p><span>On assiste &agrave; des affaires pionni&egrave;res qui fa&ccedil;onnent la jurisprudence et &agrave; des actions collectives d&rsquo;ayants droit cherchant &agrave; d&eacute;fendre leurs int&eacute;r&ecirc;ts face aux g&eacute;ants de l&rsquo;IA. Parall&egrave;lement, le contentieux administratif et r&eacute;glementaire &eacute;merge : recours contre certaines dispositions du AI Act, ou d&eacute;cisions des autorit&eacute;s nationales de suspendre des services d&rsquo;IA (comme l&rsquo;Italie l&rsquo;a fait temporairement pour ChatGPT en 2023 pour des raisons de donn&eacute;es personnelles).</span></p>
<p><span>Nous pr&eacute;sentons ici les d&eacute;cisions et affaires marquantes, structur&eacute;es entre (A) celles relatives aux cr&eacute;ations g&eacute;n&eacute;r&eacute;es par IA et (B) celles concernant les bases de donn&eacute;es/algorithmes et donn&eacute;es d&rsquo;entra&icirc;nement. Nous signalerons les divergences &eacute;ventuelles entre juridictions nationales et l&rsquo;influence des affaires &eacute;trang&egrave;res le cas &eacute;ch&eacute;ant.</span></p>
<h3><strong><span>A. Cr&eacute;ations g&eacute;n&eacute;r&eacute;es par IA &ndash; jurisprudence et affaires</span></strong></h3>
<p><span>Jurisprudence europ&eacute;enne sur le droit d&rsquo;auteur des logiciels et cr&eacute;ations assist&eacute;es : La CJUE a rendu des arr&ecirc;ts de principe sur la port&eacute;e du droit d&rsquo;auteur dans le contexte technologique, qui s&rsquo;appliquent indirectement &agrave; l&rsquo;IA. Par exemple, dans SAS Institute c. World Programming (C-406/10, 2012), la Cour a jug&eacute; que seul le code d&rsquo;un logiciel est prot&eacute;g&eacute;, pas les fonctionnalit&eacute;s ou le langage de programmation . Transpos&eacute; &agrave; l&rsquo;IA, cela signifie qu&rsquo;un tiers peut r&eacute;impl&eacute;menter les fonctionnalit&eacute;s d&rsquo;un mod&egrave;le IA (algorithme) tant qu&rsquo;il ne copie pas le code source original. De m&ecirc;me, l&rsquo;arr&ecirc;t Infopaq (C-5/08, 2009) a fix&eacute; le crit&egrave;re d&rsquo;originalit&eacute; (&laquo; cr&eacute;ation intellectuelle propre &agrave; l&rsquo;auteur &raquo;) que les tribunaux nationaux utilisent pour &eacute;valuer des &oelig;uvres cr&eacute;&eacute;es avec assistance d&rsquo;ordinateur. A ce jour, aucune affaire n&rsquo;est remont&eacute;e &agrave; la CJUE sp&eacute;cifiquement sur &laquo; une &oelig;uvre g&eacute;n&eacute;r&eacute;e par IA a-t-elle droit &agrave; la protection ? &raquo;. On s&rsquo;attend cependant &agrave; ce que la CJUE soit saisie dans les ann&eacute;es &agrave; venir, par exemple si une juridiction nationale de l&rsquo;UE devait trancher qu&rsquo;une image 100% IA n&rsquo;est pas prot&eacute;geable et qu&rsquo;une partie conteste sur le terrain du droit de l&rsquo;UE.</span></p>
<p><span>D&eacute;cisions nationales r&eacute;centes sur les &oelig;uvres IA : Plusieurs tribunaux nationaux ont d&eacute;j&agrave; eu &agrave; se prononcer sur des litiges impliquant des contenus g&eacute;n&eacute;r&eacute;s par IA ou sur l&rsquo;utilisation d&rsquo;&oelig;uvres par des IA. Par exemple :</span></p>
<ul>
    <li>
        <p><span>En France, le Tribunal judiciaire de Paris a constat&eacute; dans une affaire de 2023 concernant un g&eacute;n&eacute;rateur d&rsquo;images que &laquo; seule une personne physique peut &ecirc;tre reconnue comme auteur &raquo;, rejetant la revendication de droit d&rsquo;auteur d&rsquo;une entreprise sur des visuels produits quasi int&eacute;gralement par IA . Cette d&eacute;cision de premi&egrave;re instance s&rsquo;aligne sur l&rsquo;orthodoxie juridique et pourrait faire jurisprudence sur l&rsquo;absence de protection des cr&eacute;ations autonomes d&rsquo;IA.</span><span><br><br></span></p>
    </li>
    <li>
        <p><span>En Allemagne, aucune d&eacute;cision publi&eacute;e n&rsquo;a encore trait&eacute; d&rsquo;une &oelig;uvre purement IA, mais les tribunaux ont consacr&eacute; depuis longtemps l&rsquo;exigence d&rsquo;apport humain (doctrine de la Sch&ouml;pfungsh&ouml;he, hauteur de cr&eacute;ation). On peut citer un obiter dictum de la Cour f&eacute;d&eacute;rale allemande (BGH) dans l&rsquo;affaire DABUS 2024 notant que cette approche vaut aussi en droit d&rsquo;auteur : pas de protection sans cr&eacute;ativit&eacute; humaine .</span><span><br><br></span></p>
    </li>
    <li>
        <p><span>Au Royaume-Uni, la jurisprudence a un r&eacute;gime sui generis pour les &oelig;uvres g&eacute;n&eacute;r&eacute;es par ordinateur (Sec.9(3) CDPA 1988), mais en 2022 l&rsquo;UK Copyright Office a refus&eacute; l&rsquo;enregistrement d&rsquo;une BD dont les images &eacute;taient g&eacute;n&eacute;r&eacute;es par IA (affaire Thaler sur l&rsquo;&oelig;uvre &ldquo;Zarya of the Dawn&rdquo;), faute d&rsquo;auteur humain. C&rsquo;est hors UE mais souvent observ&eacute; par analogie.</span><span><br><br></span></p>
    </li>
</ul>
<p><span>Affaires li&eacute;es &agrave; la musique et &agrave; l&rsquo;audiovisuel g&eacute;n&eacute;r&eacute;s par IA : L&rsquo;ann&eacute;e 2023 a vu des controverses m&eacute;diatiques comme la chanson &ldquo;fake Drake&rdquo; g&eacute;n&eacute;r&eacute;e par IA imitant la voix d&rsquo;artistes c&eacute;l&egrave;bres. Si ces cas n&rsquo;ont pas encore donn&eacute; lieu &agrave; un jugement dans l&rsquo;UE, ils ont suscit&eacute; des mises en demeure et retraits pour atteinte aux droits voisins des artistes-interpr&egrave;tes et producteurs. On peut s&rsquo;attendre &agrave; des actions juridiques si le ph&eacute;nom&egrave;ne prend de l&rsquo;ampleur. D&rsquo;ores et d&eacute;j&agrave;, les majors de la musique (UMG, Sony&hellip;) en Europe ont fait pression sur les plateformes pour bannir ce type de contenu, brandissant la menace de la contrefa&ccedil;on (pour reproduction non autoris&eacute;e de la composition musicale originale, ou pour violation des droits voisins si l&rsquo;IA utilise des enregistrements existants comme mat&eacute;riau). En France, la SACEM a ouvert en 2023 un chantier sur la musique assist&eacute;e par IA, et pourrait &agrave; terme appuyer des proc&egrave;s pilotes contre des exploitations jug&eacute;es illicites.</span></p>
<p><span>Affaires embl&eacute;matiques 2023&ndash;2025 sur l&rsquo;entra&icirc;nement non autoris&eacute; d&rsquo;IA (OpenAI, Meta, Stability AI) : Plusieurs proc&eacute;dures, parfois collectives, ont &eacute;t&eacute; lanc&eacute;es r&eacute;cemment en Europe contre des entreprises d&rsquo;IA accus&eacute;es d&rsquo;utiliser des &oelig;uvres sans autorisation pour entra&icirc;ner leurs mod&egrave;les :</span></p>
<ul>
    <li>
        <p><span>En France (2025) : Syndicats d&rsquo;auteurs c. Meta (Llama) &ndash; Le 6 mars 2025, un regroupement d&rsquo;organisations d&rsquo;auteurs et &eacute;diteurs (SNE, SGDL, SNAC) a assign&eacute; Meta devant le Tribunal judiciaire de Paris, accusant l&rsquo;entreprise d&rsquo;avoir utilis&eacute; massivement des &oelig;uvres litt&eacute;raires prot&eacute;g&eacute;es pour entra&icirc;ner son mod&egrave;le LLaMA sans autorisation . L&rsquo;enqu&ecirc;te des demandeurs a r&eacute;v&eacute;l&eacute; l&rsquo;utilisation par Meta d&rsquo;une base de donn&eacute;es nomm&eacute;e &ldquo;Books3&rdquo; contenant le texte int&eacute;gral d&rsquo;environ 200 000 livres (dont de nombreux livres fran&ccedil;ais) . Meta aurait admis dans un proc&egrave;s am&eacute;ricain connexe avoir eu recours &agrave; &ldquo;Books3&rdquo; pour LLaMA . Les syndicats all&egrave;guent donc une violation du droit d&rsquo;auteur &agrave; grande &eacute;chelle et un parasitisme (appropriation des investissements d&rsquo;autrui) . Ils demandent au juge de constater la contrefa&ccedil;on et d&rsquo;ordonner le retrait/destruction des copies d&rsquo;&oelig;uvres utilis&eacute;es sans autorisation, ainsi qu&rsquo;une compensation financi&egrave;re . Cette affaire, tr&egrave;s m&eacute;diatis&eacute;e, est la premi&egrave;re du genre en Europe continentale. Elle soul&egrave;vera en d&eacute;fense la question du text mining : Meta pourra-t-elle invoquer l&rsquo;exception de text and data mining ? En l&rsquo;occurrence, l&rsquo;exception de l&rsquo;article 4 ne s&rsquo;applique pas si les titulaires ont r&eacute;serv&eacute; leurs droits. Or ici, &ldquo;Books3&rdquo; semble avoir &eacute;t&eacute; constitu&eacute;e sans consentement ; il n&rsquo;y a pas d&rsquo;indication que les &eacute;diteurs avaient &ldquo;opt-out&rdquo;, donc Meta pourrait arguer que le TDM &eacute;tait licite faute de r&eacute;serve. Les plaignants contestent implicitement, en parlant de violation du CPI fran&ccedil;ais (articles L.111-1 et suiv.) , donc ils estiment que l&rsquo;exception TDM ne saurait couvrir un usage aussi massif et purement commercial. Le juge fran&ccedil;ais devra possiblement poser une question pr&eacute;judicielle &agrave; la CJUE sur l&rsquo;interpr&eacute;tation de l&rsquo;article 4 de la directive 2019/790, &agrave; savoir si un usage de type LLaMA entre dans l&rsquo;exception. &Agrave; noter que les demandeurs citent aussi le contexte du AI Act adopt&eacute;, mentionnant que celui-ci impose aux fournisseurs d&rsquo;IA de fournir un r&eacute;sum&eacute; des donn&eacute;es d&rsquo;entra&icirc;nement prot&eacute;g&eacute;es &nbsp;&ndash; bien que le AI Act n&rsquo;&eacute;tait pas encore en vigueur lors des faits, cela sert &agrave; &eacute;tayer l&rsquo;ill&eacute;gitimit&eacute; du comportement de Meta au regard de l&rsquo;esprit du droit europ&eacute;en naissant.</span><span><br><br></span></p>
    </li>
    <li>
        <p><span>Au Royaume-Uni (proc&egrave;s Getty Images c. Stability AI) : En janvier 2023, Getty Images (leader de la photo d&rsquo;archives) a engag&eacute; une proc&eacute;dure devant la High Court de Londres contre la startup Stability AI, d&eacute;veloppeur du mod&egrave;le Stable Diffusion qui g&eacute;n&egrave;re des images &agrave; partir de textes . Getty accuse Stability d&rsquo;avoir aspir&eacute; des millions de ses images prot&eacute;g&eacute;es (via la base LAION-5B) sans permission pour entra&icirc;ner son IA, et d&rsquo;en reproduire des &eacute;l&eacute;ments dans les images g&eacute;n&eacute;r&eacute;es pour les utilisateurs &nbsp;. Les demandes portent sur la contrefa&ccedil;on par reproduction (copie des images dans le dataset d&rsquo;entra&icirc;nement et dans les outputs si des &eacute;l&eacute;ments reconnaissables de photos Getty y apparaissent) &nbsp;, ainsi que sur la violation de marques (le mod&egrave;le a parfois g&eacute;n&eacute;r&eacute; des images avec le watermark Getty &ndash; signe distinctif &ndash; incrust&eacute;). Cette affaire est embl&eacute;matique et fera l&rsquo;objet d&rsquo;un proc&egrave;s en juin 2025 &agrave; Londres, d&rsquo;une dur&eacute;e pr&eacute;vue de trois semaines . Ce sera l&rsquo;un des tout premiers jugements de fond au monde sur l&rsquo;IA et le droit d&rsquo;auteur, tr&egrave;s attendu pour ses implications globales. Bien que le Royaume-Uni ne soit plus membre de l&rsquo;UE, le raisonnement juridique pourrait influencer l&rsquo;UE. D&rsquo;ailleurs, Getty a port&eacute; plainte aussi aux &Eacute;tats-Unis contre Stability, mais le UK a &eacute;t&eacute; choisi pour aller plus vite. En d&eacute;cembre 2023, une d&eacute;cision interm&eacute;diaire de la High Court a refus&eacute; de rejeter les arguments de Getty en contrefa&ccedil;on, estimant qu&rsquo;il y a des questions s&eacute;rieuses &agrave; juger (notamment : la cr&eacute;ation de repr&eacute;sentations interm&eacute;diaires &laquo; bruit&eacute;es &raquo; des images pendant l&rsquo;entra&icirc;nement constitue-t-elle une copie illicite ? Les images produites sortant du mod&egrave;le peuvent-elles &ecirc;tre consid&eacute;r&eacute;es comme reproduisant une partie substantielle des images Getty originales ?) &nbsp;. Stability AI conteste en arguant que l&rsquo;entra&icirc;nement rel&egrave;ve d&rsquo;un usage technique transformateur et qu&rsquo;aucune image g&eacute;n&eacute;r&eacute;e n&rsquo;est &eacute;quivalente ou substituable aux originales (argument proche du fair use am&eacute;ricain). Le jugement UK sera scrut&eacute; dans l&rsquo;UE, et pourrait encourager d&rsquo;autres titulaires (&eacute;diteurs, producteurs) &agrave; lancer des actions similaires sur le continent. Notons que la CJUE pourrait &ecirc;tre amen&eacute;e, si un litige similaire survenait dans un &Eacute;tat membre, &agrave; se prononcer sur la notion de reproduction partielle substantielle dans le contexte d&rsquo;IA, et sur l&rsquo;&eacute;quilibre avec l&rsquo;exception de reproduction temporaire technologique (InfoSoc art.5(1)) ou TDM (CDSM art.4).</span><span><br><br></span></p>
    </li>
    <li>
        <p><span>Autres actions : D&rsquo;autres entreprises d&rsquo;IA font face &agrave; des contentieux naissants en Europe. OpenAI (&eacute;diteur de ChatGPT) a &eacute;t&eacute; mise en demeure en Pologne par une association d&rsquo;auteurs en 2023 pour l&rsquo;usage de textes litt&eacute;raires polonais dans GPT sans compensation &ndash; sans proc&eacute;dure judiciaire annonc&eacute;e pour l&rsquo;instant. En Italie, le blocage temporaire de ChatGPT en mars-avril 2023 par le r&eacute;gulateur de la vie priv&eacute;e (GPDP) a aussi soulev&eacute; la question collat&eacute;rale de l&rsquo;origine des donn&eacute;es de ChatGPT, dont des &eacute;ventuels contenus sous droit d&rsquo;auteur, mais l&rsquo;angle juridique &eacute;tait la protection des donn&eacute;es personnelles. Il n&rsquo;emp&ecirc;che que cela a pouss&eacute; OpenAI &agrave; offrir des moyens de d&eacute;sactivation de l&rsquo;utilisation des conversations des utilisateurs pour entra&icirc;ner les mod&egrave;les, et &agrave; promettre plus de transparence &ndash; ce qui anticipe les exigences du AI Act.</span><span><br><br></span></p>
    </li>
</ul>
<p><span>Contentieux brevets &ndash; IA inventeur : Comme &eacute;voqu&eacute;, les affaires DABUS ont marqu&eacute; le domaine des brevets. Apr&egrave;s le refus de l&rsquo;OEB (d&eacute;cision publi&eacute;e en janvier 2020 ) confirmant que DABUS ne peut &ecirc;tre inventeur, les porteurs du projet DABUS ont tent&eacute; des recours dans divers pays. La jurisprudence converge : la Haute Cour de Justice du Royaume-Uni (2021), la Cour d&rsquo;appel f&eacute;d&eacute;rale des &Eacute;tats-Unis (2022), la Cour supr&ecirc;me d&rsquo;Australie (2022) et la Cour f&eacute;d&eacute;rale allemande (2024) ont tous rejet&eacute; l&rsquo;id&eacute;e d&rsquo;un inventeur non humain . L&rsquo;enjeu &agrave; court terme est donc r&eacute;gl&eacute; : un brevet doit avoir un inventeur humain, sinon il est refus&eacute; ou invalid&eacute;. Une question connexe surgira : si une invention est en partie g&eacute;n&eacute;r&eacute;e par IA mais qu&rsquo;un humain est inventeur, cela peut-il affecter l&rsquo;appr&eacute;ciation de l&rsquo;activit&eacute; inventive (par ex. doit-on consid&eacute;rer l&rsquo;IA comme faisant partie de l&rsquo;&eacute;tat de la technique ou comme outil normal de l&rsquo;homme du m&eacute;tier) ? Ces points ont &eacute;t&eacute; soulev&eacute;s doctrinalement, mais pas encore arbitr&eacute;s par une cour. L&rsquo;OEB a ins&eacute;r&eacute; dans ses Directives 2023 quelques notes sur l&rsquo;IA, mais pas de r&egrave;gle sp&eacute;ciale pour l&rsquo;appr&eacute;ciation : on la traite comme tout outil de conception assist&eacute;e par ordinateur.</span></p>
<p><span>Droit des marques et IA &ndash; d&eacute;cisions notables : Peu de contentieux de marque li&eacute;s &agrave; l&rsquo;IA sont parvenus devant les tribunaux, mais on peut citer des aspects naissants : l&rsquo;utilisation d&rsquo;IA pour g&eacute;n&eacute;rer des logos a pu causer des conflits (ex. une IA g&eacute;n&eacute;rant un logo ressemblant trop &agrave; une marque existante pourrait engager la responsabilit&eacute; du fournisseur ou de l&rsquo;utilisateur). En 2022, un tribunal n&eacute;erlandais a trait&eacute; un cas o&ugrave; une IA de g&eacute;n&eacute;ration de visuels avait produit une image proche d&rsquo;un visuel prot&eacute;g&eacute;, soulevant une question de comparaison de droits, mais l&rsquo;affaire s&rsquo;est r&eacute;gl&eacute;e &agrave; l&rsquo;amiable. Un autre aspect est l&rsquo;usage d&rsquo;IA dans la publicit&eacute; : en France, le Code de la consommation a &eacute;t&eacute; modifi&eacute; en 2023 pour obliger les influenceurs &agrave; indiquer quand ils utilisent des images g&eacute;n&eacute;r&eacute;es ou modifi&eacute;es par IA dans leurs pubs (loi du 9 juin 2023) . Ce n&rsquo;est pas du droit des marques directement, mais cela rejoint la lutte contre la tromperie visuelle. &Agrave; l&rsquo;avenir, si une IA conversationnelle utilise des noms de marques de fa&ccedil;on trompeuse, cela pourrait donner lieu &agrave; des litiges en concurrence d&eacute;loyale ou en dilution de marque. Pour le moment, l&rsquo;attention reste centr&eacute;e sur le droit d&rsquo;auteur.</span></p>
<p><span>Contentieux administratif et r&eacute;gulation : Sur le plan du contr&ocirc;le r&eacute;glementaire, on voit appara&icirc;tre des recours contre les nouvelles lois ou d&eacute;cisions administratives. Par exemple, plusieurs associations ont exprim&eacute; l&rsquo;intention de contester certaines dispositions du AI Act devant la Cour de justice de l&rsquo;UE, &eacute;ventuellement via un recours en annulation (bien que la l&eacute;gitimit&eacute; active soit limit&eacute;e) ou en tout cas d&rsquo;en tester l&rsquo;interpr&eacute;tation. Un point litigieux pourrait &ecirc;tre la d&eacute;finition large de &laquo; fournisseur &raquo; de mod&egrave;le IA et l&rsquo;application extraterritoriale : un fournisseur &eacute;tranger pourrait contester la validit&eacute; de l&rsquo;obligation de se conformer au droit d&rsquo;auteur de l&rsquo;UE pour des actes d&rsquo;entra&icirc;nement r&eacute;alis&eacute;s hors UE , y voyant une violation du droit international. Cela pourrait monter via un litige national (une autorit&eacute; inflige une amende, l&rsquo;entreprise conteste devant une cour de l&rsquo;UE). Par ailleurs, la mise en place des autorit&eacute;s nationales de supervision de l&rsquo;IA suscite des d&eacute;bats. L&rsquo;AI Act demande &agrave; chaque pays de d&eacute;signer une autorit&eacute; comp&eacute;tente. L&rsquo;Espagne a d&eacute;j&agrave; cr&eacute;&eacute; l&rsquo;AESIA (Agence espagnole IA) en 2022 . D&rsquo;autres pays n&rsquo;ont pas encore d&eacute;cid&eacute; s&rsquo;ils confieront cette mission &agrave; une agence existante (par ex. la CNIL en France pourrait h&eacute;riter de la supervision des IA en lien avec les donn&eacute;es). Des contentieux pourraient na&icirc;tre du chevauchement de comp&eacute;tences : par ex. une autorit&eacute; de protection des donn&eacute;es vs une autorit&eacute; PI vs l&rsquo;autorit&eacute; IA, si une IA viole &agrave; la fois GDPR et droit d&rsquo;auteur, qui prime ? On a vu un cas en Italie o&ugrave; l&rsquo;autorit&eacute; de donn&eacute;es a pris l&rsquo;initiative (pour ChatGPT), sans qu&rsquo;il y ait d&rsquo;autorit&eacute; IA encore. Lorsque les autorit&eacute;s IA seront op&eacute;rationnelles (sans doute en 2025), leurs d&eacute;cisions (ex. ordonner le retrait d&rsquo;un mod&egrave;le non conforme, ou sanctionner un fournisseur) feront probablement l&rsquo;objet de recours juridictionnels de la part des entreprises vis&eacute;es. Il s&rsquo;agira alors d&rsquo;un contentieux administratif nouveau, que les juridictions devront g&eacute;rer, avec en toile de fond les questions de PI (par ex. une entreprise sanctionn&eacute;e pour ne pas avoir publi&eacute; la liste des jeux de donn&eacute;es pourra-t-elle contester en disant qu&rsquo;elle prot&eacute;geait des secrets d&rsquo;affaires ou que l&rsquo;obligation porte atteinte &agrave; ses droits ?).</span></p>
<p><span>&Eacute;volutions r&eacute;centes &agrave; l&rsquo;international influen&ccedil;ant l&rsquo;UE : Enfin, bien que la question porte sur l&rsquo;UE, il convient de signaler des d&eacute;cisions &eacute;trang&egrave;res de 2023-2025 ayant un retentissement en Europe. Aux &Eacute;tats-Unis, plusieurs class actions d&rsquo;auteurs et artistes contre OpenAI, Meta et Stability AI ont &eacute;t&eacute; lanc&eacute;es (ex. Authors Guild et al. v. OpenAI en 2023, Sarah Silverman et al. v. OpenAI/Meta 2023, Andersen v. Stability AI 2023). Ces affaires all&egrave;guent une violation massive du copyright par l&rsquo;entra&icirc;nement de mod&egrave;les sur des corpus entiers de livres ou d&rsquo;images sans autorisation. Elles en sont encore aux &eacute;tapes pr&eacute;liminaires (aucun jugement sur le fond fin 2024), mais une d&eacute;cision d&eacute;favorable aux entreprises d&rsquo;IA aux USA (par exemple jugeant que le fair use ne s&rsquo;applique pas &agrave; l&rsquo;entra&icirc;nement IA &agrave; grande &eacute;chelle) pourrait encourager encore plus d&rsquo;ayants droit europ&eacute;ens &agrave; poursuivre en Europe, o&ugrave; le terrain juridique leur est a priori plus favorable (pas de fair use, exceptions TDM encadr&eacute;es). &Agrave; l&rsquo;inverse, si les tribunaux am&eacute;ricains estiment l&rsquo;usage transformative et donc l&eacute;gal, les entreprises d&rsquo;IA tenteront peut-&ecirc;tre d&rsquo;invoquer ces analyses en Europe, bien que le droit diff&egrave;re. Au Royaume-Uni, outre Getty v. Stability, une autre affaire potentielle est celle de Toei Animation v. AI (non confirm&eacute;e publiquement, mentionn&eacute;e dans la presse) o&ugrave; un studio japonais aurait mandat&eacute; des avocats UK pour agir contre une startup europ&eacute;enne ayant entra&icirc;n&eacute; un mod&egrave;le vid&eacute;o sur ses dessins anim&eacute;s &ndash; on voit ainsi que les titulaires extra-europ&eacute;ens peuvent aussi choisir l&rsquo;Europe pour d&eacute;fendre leurs droits contre des acteurs locaux.</span></p>
<p><span>Perspective d&rsquo;avenir des contentieux : Les d&eacute;cisions rendues en 2023&ndash;2025 confirment globalement la coh&eacute;rence du cadre europ&eacute;en : pas de droits nouveaux pour l&rsquo;IA, application stricte du droit d&rsquo;auteur existant (originalit&eacute; humaine), mais ouverture contr&ocirc;l&eacute;e via les exceptions (TDM) et obligation de respecter celles-ci (via AI Act). Les tribunaux europ&eacute;ens sont pour l&rsquo;instant align&eacute;s sur la protection des cr&eacute;ateurs humains, ce qui est en phase avec les grandes doctrines mondiales (y compris celle rappel&eacute;e par le BGH allemand en 2024 faisant le parall&egrave;le entre PI et IA en brevet et en copyright ). Il faudra suivre la mise en &oelig;uvre du AI Act, dont la pleine application interviendra d&rsquo;ici 2025&ndash;2026 : ses dispositions transparence des donn&eacute;es d&rsquo;entra&icirc;nement et respect du droit d&rsquo;auteur pourront &ecirc;tre invoqu&eacute;es devant les juges, soit par les autorit&eacute;s de supervision, soit par les cr&eacute;ateurs comme support de leurs demandes (m&ecirc;me si le non-respect du AI Act n&rsquo;implique pas automatiquement contrefa&ccedil;on, cela renforcera la position des cr&eacute;ateurs). Enfin, l&rsquo;UE pourrait voir d&rsquo;ici l&agrave; ses premi&egrave;res d&eacute;cisions de justice sur la responsabilit&eacute; : par exemple, si un g&eacute;n&eacute;rateur d&rsquo;images IA produit une image tr&egrave;s proche d&rsquo;une photo prot&eacute;g&eacute;e et qu&rsquo;un utilisateur l&rsquo;exploite commercialement, la question d&rsquo;une &eacute;ventuelle responsabilit&eacute; partag&eacute;e du fournisseur du mod&egrave;le pourrait se poser. Ces sujets sont encore th&eacute;oriques mais n&rsquo;attendent que le cas d&rsquo;esp&egrave;ce pour arriver en salle d&rsquo;audience.</span></p>
<p><span>En conclusion, l&rsquo;encadrement europ&eacute;en de l&rsquo;IA et de la PI se construit par touches successives : la l&eacute;gislation se met &agrave; jour (AI Act, exceptions TDM), les politiques se dessinent (codes de conduite, &eacute;tudes prospectives) et la jurisprudence commence &agrave; donner des signaux clairs (primaut&eacute; de la cr&eacute;ativit&eacute; humaine, condamnation d&rsquo;usages non autoris&eacute;s d&rsquo;&oelig;uvres par les IA). L&rsquo;UE cherche la coh&eacute;rence interne et le leadership externe en la mati&egrave;re, confrontant son mod&egrave;le r&eacute;glementaire aux mod&egrave;les plus permissifs (USA) ou plus dirigistes (Chine). Les divergences entre &Eacute;tats membres existent sur les modalit&eacute;s, mais tous s&rsquo;accordent sur l&rsquo;objectif d&rsquo;une IA &eacute;thique et de confiance, compatible avec les droits des cr&eacute;ateurs. Les ann&eacute;es 2023&ndash;2025 auront &eacute;t&eacute; charni&egrave;res, et l&rsquo;on s&rsquo;achemine vers un cadre europ&eacute;en sans doute plus affin&eacute; encore par les retours d&rsquo;exp&eacute;rience, les d&eacute;cisions de justice et les n&eacute;gociations internationales, afin de garantir que l&rsquo;IA soit une opportunit&eacute; d&rsquo;innovation sans &eacute;roder le socle de la propri&eacute;t&eacute; intellectuelle qui prot&egrave;ge et incite la cr&eacute;ation humaine en Europe.</span></p>
<p><span>Sources: R&egrave;glement (UE) 2024/1689 (AI Act) ; Directive 2001/29/CE ; Directive 96/9/CE ; D&eacute;cision OEB DABUS 2019 ; BGH, DABUS, 11 juin 2024 ; R&eacute;solution PE 2020/2015(INI) ; Question parl. E-000479/2023 ; Proposition de loi AN n&deg;1630 (2023) ; Action SNE/SGDL c. Meta 2025 ; Proc&egrave;s Getty Images v. Stability AI (High Court UK) ; Blog Kluwer Copyright (Paul Keller) ; &Eacute;tude EPRS 2025 (T. Marcelin)&nbsp;</span></p>
<p><br></p>
<p><br></p>
<p><br></p>
<div style="bottom: 10px; right: 10px; position: absolute;"><a href="https://wordtohtml.net/?utm_source=wth_free_link&utm_medium=external" target="_blank" style="font-size:11px; color: #d0d0d0;">Convert Word or PDF documents to HTML</a></p>