<div class="country-content">
    <h2>Canada at the Crossroads: AI vs. the Dogma of the Human Author</h2>
    <div class="abstract-box">
        <p><strong>Summary:</strong> A land of technological innovation, Canada faces a major legal dilemma. While its
            AI ecosystem is
            booming, its intellectual property (IP) framework remains anchored in a strict humanist tradition. Between
            the
            Patent Appeal Board's categorical refusal of the "robot-inventor" and the uncertainties surrounding model
            training, Canadian law is currently in a state of gestation, torn between the need for modernization and the
            protection of human creators.</p>
    </div>

    <h3>I. The State of Black-Letter Law: The Orthodoxy of Human Creation</h3>
    <p>Current Canadian law is characterized by a notable resistance to recognizing AI as a legal subject, creating de
        facto"protection vacuums" for purely algorithmic creations.</p>

    <h4>A. The "Human Author" deadlock</h4>
    <p>In copyright matters, the Copyright Act does not explicitly define "author," but jurisprudence—most notably
        the landmark case CCH Canadian Ltd. v. Law Society of Upper Canada (2004)—requires that a work result
        from an exercise of "skill and judgment" by a human.</p>
    <ul>
        <li><strong>The immediate consequence:</strong> A work generated autonomously by an AI falls outside the scope
            of
            protection. While AI assistance is tolerated, the threshold of human intervention required remains a
            "gray zone" in case law.</li>
        <li><strong>The Suryast incident:</strong> In 2021, the Canadian Intellectual Property Office (CIPO) registered
            an
            image listing an AI named "RAGHAV" as a co-author. This created a troubling administrative
            precedent, currently being challenged before the Federal Court, illustrating the fragility of existing
            practices.</li>
    </ul>

    <h4>B. Intransigence in patent law</h4>
    <p>In the field of industrial property, the Canadian position has now crystallized. The Patent Act mandates the
        designation of a nominal inventor.
        The Thaler Jurisprudence (2025): In June 2025, the Patent Appeal Board confirmed the rejection of
        the patent application for the AI DABUS. The Board ruled that only human beings can be inventors.
        This decision aligns Canada with the international consensus, effectively closing the door on
        autonomous inventions.</p>

    <h4>C. The vulnerability of training data (Inputs)</h4>
    <p>This is the "blind spot" of the Canadian system. Unlike the European Union, Canada possesses neither a sui
        generis database right (having rejected the "sweat of the brow" theory since the Tele-Direct ruling) nor an
        explicit Text and Data Mining (TDM) exception.</p>
    <ul>
        <li><strong>Legal Insecurity:</strong> The massive ingestion of protected works to train models occurs in a
            total vacuum.
            Developers can only rely on general exceptions, such as Fair Dealing (for research or private study),
            the applicability of which to commercial training is highly uncertain.</li>
    </ul>

    <h3>II. Reform Projects and Political Trends: Consultative Caution</h3>
    <p>Facing the urgency of the situation, the Canadian government has held multiple consultations since 2021
        without rushing into legislative reform.</p>

    <h4>A. Toward increased transparency rather than revolution?</h4>
    <p>The February 2025 synthesis report ("What We Heard") reveals a lack of consensus on creating a specific
        copyright category for AI. Instead, a strong trend is emerging in favor of transparency.</p>
    <ul>
        <li><strong>Disclosure Obligations:</strong> The government is considering requiring developers to declare the
            sources of their training data. This pragmatic measure would allow rights holders to verify the
            use of their works without overhauling the fundamental architecture of copyright law.</li>
    </ul>

    <h4>B. The Text and Data Mining (TDM) project</h4>
    <p>The question of a TDM exception deeply divides stakeholders. While tech players demand an opening to
        support innovation, cultural industries are calling for a system of remunerated licenses. For now, Ottawa seems
        to favor targeted adjustments over a global overhaul, leaving doubt as to whether an exception comparable to the
        European model will be introduced.</p>

    <h3>III. Current Litigation: The Moment of Truth</h3>
    <p>While the legislator bides its time, the courts are now seized with cases that could redefine the Canadian legal
        landscape.</p>

    <h4>A. The Suryast case (CIPPIC v. Sahni): The trial of the AI-Author</h4>
    <p>The action brought before the Federal Court in July 2024 by the CIPPIC clinic seeks to expunge the registration
        of the image Suryast, which was co-signed by an AI.
        The Stakes: This "test case" will force the Court to decide once and for all: can the notion of "author"
        extend to non-humans? A negative response, expected by most legal scholars—would lock Canadian
        jurisprudence into a strict anthropocentric line.</p>

    <h4>B. The Thaler decision (2025): The end of the patent illusion</h4>
    <p>The Patent Appeal Board’s decision on June 5, 2025, in Re Thaler, constitutes a major landmark. By refusing
        inventor status to the AI DABUS in the name of the patent "social contract" (disclosure in exchange for a
        monopoly), the Board established a solid doctrinal safeguard that the Federal Court is unlikely to challenge.
    </p>

    <h3>Conclusion</h3>
    <p>Canada is navigating by sight but with a clear method. By refusing to succumb to the allure of "electronic
        personhood" while preparing the ground for training data regulation, Ottawa is seeking a middle path. Canadian
        law in 2026 remains a law of human authors, for humans. It remains to be seen whether this orthodoxy can
        withstand the economic pressure of AI giants who, lacking legal certainty on data, might be tempted to relocate
        their training activities.</p>
</div>