<div class="country-content">
    <h2>The British Model Put to the AI Test: Between Copyright Tradition and "Text and Data Mining" Pragmatism</h2>
    <div class="abstract-box">
        <p><strong>Summary:</strong> In 2026, the United Kingdom continues to cultivate its legal singularity in the
            face of Artificial
            Intelligence challenges. Armed with visionary legislation dating back to 1988 on computer-generated works,
            British law currently navigates between a strict orthodoxy regarding patents and a drive for economic
            openness
            via new exceptions for data mining. An analysis of a system attempting to reconcile the protection of human
            investment with the rise of automation.</p>
    </div>

    <h3>I. The State of Black-Letter Law: The British Anomaly of "Computer-Generated Works"</h3>
    <p>The British legal framework is distinguished by a striking dichotomy: historical audacity in copyright law,
        contrasting with an assumed conservatism in the field of patents.</p>

    <h4>A. Visionary protection for works without a human author</h4>
    <p>As early as 1988, the British legislator anticipated the era of machine creation. The Copyright, Designs and
        Patents Act 1988 (CDPA) contains a unique provision, Section 9(3), which creates the category of
        "computer-generated works."Unlike most civil law jurisdictions that require the "stamp of the author's
        personality," the UK grants protection, albeit reduced to 50 years, to works lacking a direct human author.
        The law operates through a pragmatic legal fiction: the author is deemed to be "the person by whom the
        arrangements necessary for the creation of the work are undertaken." This approach maintains a chain of human
        ownership, even for automatically generated content, by valuing the investor or system operator rather than the
        machine itself. If human intervention is substantial (editing, selection), the work falls under the classic
        copyright
        regime; if the contribution is minimal, the specific regime for computer-generated works applies, thus avoiding
        a legal vacuum.</p>

    <h4>B. The "Human Inventor" deadlock in patent law</h4>
    <p>Conversely, patent law remains hermetic to the recognition of AI. The UK Supreme Court has confirmed, in
        line with US jurisprudence, that an AI cannot be qualified as an inventor. Only a natural person or a legal
        entity
        can claim this title.
        In practice, this position imposes a degree of legal gymnastics on applicants: to patent an invention resulting
        from AI, it is imperative to identify a human inventor who directed or implemented the inventive process. AI
        remains confined to the status of a sophisticated tool, devoid of legal personality or autonomous inventive
        capacity.</p>

    <h4>C. Protecting investment: Databases and the transparency gap</h4>
    <p>The UK maintains a sui generis database right, protecting the substantial investment made in obtaining or
        verifying content. Theoretically, an AI-generated database could benefit from this protection if the investment
        criterion is met.
        However, a major gap persists regarding AI algorithms and models themselves. Current law confers no
        specific status upon them. Their protection relies on the classic triptych: copyright on source code, trade
        secrets,
        and contracts. More concerning for creators, current law imposes no obligation for transparency or traceability
        of training data, leaving the opacity of datasets governed solely by the balance of technological power.</p>

    <h3>II. Reform Projects and Political Trends: The "TDM" Pivot</h3>
    <p>Facing global competition, the British government clarified its doctrine in 2025, prioritizing economic
        attractiveness over dogmatic overhaul.</p>

    <h4>A. The Government Response of October 2025: Stability and Openness</h4>
    <p>Following a vast public consultation conducted between 2024 and 2025, the executive released its findings in
        the Government Response to Consultation in October 2025. Two major axes emerged. First, the government
        refuses to modify the rules for protecting AI-generated works, deeming the CDPA 1988 framework sufficient.
        Second, and this is the major shift, it announced the introduction of a Text and Data Mining (TDM) exception
        covering all purposes, including commercial ones.
        This future exception, conditioned on lawful access to data, marks a rupture. It aims to transform the UK into a
        "safe harbor" for model training, at the risk of upsetting the creative industries.</p>

    <h4>B. The Parliamentary rebellion for transparency</h4>
    <p>While the government pushes for the deregulation of data mining, Parliament is echoing the concerns of
        creators. The debate surrounding the Data (Use and Access) Bill 2025 has crystallized these tensions.
        Amendments led by Baroness Beeban Kidron in the House of Lords, supported by major cultural figures, aim
        to impose a transparency obligation on the use of protected content by AI. Although contested by the
        government in the Commons, this legislative initiative demonstrates intense political pressure to rebalance the
        scales in favor of rights holders.</p>

    <h3>III. Current Litigation: "Getty" Jurisprudence as a Compass</h3>
    <p>In the absence of specific legislation on model training, eyes have turned toward the courts. 2025 was marked
        by a defining decision.</p>

    <h4>A. Getty Images v. Stability AI (High Court, 4 November 2025)</h4>
    <p>This High Court judgment constitutes the first major cornerstone of British jurisprudence in this area. Getty
        Images alleged that Stability AI used 12 million images to train its Stable Diffusion model.
        The Court delivered a nuanced ruling, favorable to technological development. It held that the mere "scraping"
        of images for training did not, in itself, constitute copyright infringement, due to a lack of evidence of
        reproduction or permanent storage of the original work within the model's outputs. Conversely, the Court
        recognized infringements regarding trademark law, notably due to the "hallucinatory" appearance of Getty
        watermarks on generated images, creating a likelihood of confusion.</p>

    <h4>B. Scope and limits of current case law</h4>
    <p>The Getty ruling draws a fine line: training is tolerated as long as it does not result in a servile reproduction
        in
        the output. However, this decision leaves gray areas, particularly regarding the precise application of fair
        dealing. As 2026 begins, the absence of other major rulings maintains an element of uncertainty that only future
        TDM legislation can definitively resolve.</p>

    <h3>Conclusion</h3>
    <p>The United Kingdom of 2026 is betting on pragmatism. By relying on an established text (CDPA 1988) to
        protect the fruits of AI while opening the data floodgates through a future TDM exception, London seeks to
        become a sanctuary for innovationâ€”even if it means managing the inevitable friction with the creative world
        through the courts.</p>
</div>