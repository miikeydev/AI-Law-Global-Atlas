<div class="country-content">
    <h2>Eastern Europe and AI: Two Models for Regulating IP in the Age of Automation (Estonia vs Russia)</h2>

    <h3>Summary</h3>
    <p>While Estonia, the European Union’s digital poster child, bets on harmonised EU rules and a liberal framework
        built around text and data mining (TDM), Russia is moving along a more interventionist—and increasingly
        judge-made—path. Between Tallinn’s legislative caution and Moscow courts’ readiness to protect “hybrid” AI
        outputs such as deepfakes, this is a tale of two legal strategies at opposite ends of the spectrum for dealing
        with the non-human author.</p>

    <h3>I. The Law as It Stands: Human-Author Orthodoxy Meets New Tools</h3>
    <p>Both jurisdictions share a conceptual baseline—AI has no legal personality. But they diverge sharply on how
        rights over training data (inputs) are managed.</p>

    <h4>A. A shared rejection of “electronic personhood”</h4>
    <p>In both Estonia and Russia, positive law remains closed to the idea of a machine-author.</p>
    <ul>
        <li><strong>Estonia:</strong> Under Estonian copyright law, the status of author is inseparable from a natural
            person. Any creation generated autonomously by AI falls, as a matter of practice, outside copyright
            protection for want of human-attributable originality—leaving it effectively unprotected and, in functional
            terms, open for reuse. The same principle carries over into patents under Estonia’s Patents Act, in line
            with the European Patent Office approach: no human inventor, no patent.</li>
        <li><strong>Russia:</strong> The Civil Code is equally strict. Articles 1228 and 1257 tie authorship to the
            citizen who has produced a creative work. Russia’s patent office (Rospatent) is portrayed as consistently
            refusing registration of outputs deemed purely artificial.</li>
    </ul>

    <h4>B. The fault line: training data (inputs)</h4>
    <p>The real divergence emerges where it matters most for AI development: lawful access to data for machine learning.
    </p>
    <ul>
        <li><strong>The Estonian model (the TDM exception):</strong> Estonia has transposed EU Directive 2019/790 (the
            DSM Directive), introducing a text and data mining exception. The result is a relatively predictable
            environment: TDM is freely permitted for research purposes, and available for commercial uses subject to a
            rightsholder opt-out. It is pro-innovation by statute—clear rules first, litigation later.</li>
        <li><strong>The Russian model (legal grey zones):</strong> Russia has no explicit TDM exception of the same
            kind. While a <em>sui generis</em> right over databases exists (Civil Code arts 1333–1336), the absence of a
            clear “fair use”-type mechanism for training leaves developers exposed to legal uncertainty and,
            potentially, large-scale infringement claims.</li>
    </ul>

    <h3>II. Reform Agendas and Political Signals: Strategic Caution vs Legislative Activism</h3>
    <p>Confronted with technological urgency, the two states adopt visibly different political postures.</p>

    <h4>A. Estonia: the discipline of international alignment</h4>
    <p>For all its reputation as a “digital nation”, Estonia has chosen not to legislate alone.</p>
    <ul>
        <li><strong>No major domestic overhaul:</strong> There is no flagship Estonian bill designed to create copyright
            for AI as such. The strategy is closer to active patience: shaping discussions within the EU and WIPO, then
            adjusting national law once an international consensus solidifies.</li>
        <li><strong>Cultural initiatives:</strong> The reported 2025 proposal by Minister Liisa-Ly Pakosta to make
            Estonian-language corpora available for AI training illustrates a pragmatic instinct: rather than inventing
            new property rights, the state facilitates lawful access to data to safeguard cultural and linguistic
            sovereignty.</li>
    </ul>

    <h4>B. Russia: legislative ferment</h4>
    <p>Moscow appears more willing to move quickly to fill perceived legal gaps.</p>
    <ul>
        <li><strong>Towards a special regime?</strong> Draft initiatives discussed at the State Duma (mentioned as early
            as 2020 and revived in 2025) have been framed as potentially allocating rights in AI-generated works to the
            owner of the algorithm.</li>
        <li><strong>Industry pressure:</strong> The music sector—here referenced via the NFMI—is depicted as lobbying
            for reforms to Civil Code article 1259 to protect synthetic voices and images, citing estimated revenue
            losses caused by “fake songs”.</li>
    </ul>

    <h3>III. Litigation Watch: Tallinn’s Silence, Moscow’s Boldness</h3>
    <p>The contrast is stark: an Estonian courtroom still waiting for its test case, versus Russian tribunals beginning
        to sketch out a pragmatic line.</p>

    <h4>A. Estonia: the absence of case law</h4>
    <p>To date, this account suggests no Estonian judgment has squarely determined the status of an AI-generated work.
        Practitioners handle the risk upstream—advising, for example, against using AI to imitate the protected style of
        well-known franchises—while courts have not yet been forced to draw boundaries. The calm is sustained by the
        clarity—and rigidity—of the statutory framework.</p>

    <h4>B. Russia: the “Deepfake” ruling (2023)</h4>
    <p>By contrast, the Moscow Arbitrazh Court is said to have issued a landmark decision on 30 November 2023 (Case
        A40-200471/23).</p>
    <ul>
        <li><strong>The facts:</strong> A deepfake video inserting actor Keanu Reeves’ face into a comedic scene was
            used without permission. The defendant argued that, because the video was generated with AI, it could not be
            protected.</li>
        <li><strong>The ruling:</strong> The court rejected that reasoning. It treated AI as a technical tool, holding
            that human intervention—script, editing, and creative choices—was sufficient to attract copyright
            protection.</li>
        <li><strong>Why it matters:</strong> The decision sets down a practical marker: using AI does not extinguish
            copyright where the human contribution is substantial. It preserves protection for hybrid works, while
            implicitly confirming the exclusion of outputs that are truly autonomous.</li>
    </ul>

    <h3>Conclusion</h3>
    <p>Estonia and Russia reflect two speeds—and two philosophies—of regulation. Estonia, faithful to its liberal,
        EU-oriented tradition, focuses on the governance of data inputs and the stability of orthodox copyright
        concepts. Russia, facing a more assertive cultural industry and operating in a different geopolitical climate,
        appears readier to bend classical legal categories—through statute or through courts—to avoid AI becoming a
        lawless zone.</p>
    <p>If Estonia is building a regulated runway for innovation, Russia is letting litigation and policy pressure redraw
        the map in real time.</p>
</div>